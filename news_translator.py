import openai
import logging
from datetime import datetime, timedelta
from typing import Dict, Optional
import hashlib
import re

logger = logging.getLogger(__name__)

class NewsTranslator:
    """ğŸ”¥ğŸ”¥ ë²ˆì—­ ë° ìš”ì•½ ì „ë‹´ í´ë˜ìŠ¤ - GPT ìœ„ì£¼, Claude ë°±ì—…"""
    
    def __init__(self, config):
        self.config = config
        
        # GPT API í´ë¼ì´ì–¸íŠ¸ (ì£¼ë ¥)
        self.openai_client = None
        if hasattr(config, 'OPENAI_API_KEY') and config.OPENAI_API_KEY:
            self.openai_client = openai.AsyncOpenAI(api_key=config.OPENAI_API_KEY)
            logger.info("âœ… GPT API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ì£¼ë ¥)")
        
        # Claude API í´ë¼ì´ì–¸íŠ¸ (ë°±ì—…)
        self.anthropic_client = None
        if hasattr(config, 'ANTHROPIC_API_KEY') and config.ANTHROPIC_API_KEY:
            try:
                import anthropic
                self.anthropic_client = anthropic.AsyncAnthropic(api_key=config.ANTHROPIC_API_KEY)
                logger.info("âœ… Claude API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ë°±ì—…)")
            except ImportError:
                logger.warning("âŒ anthropic ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ: pip install anthropic")
            except Exception as e:
                logger.warning(f"âŒ Claude API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ë²ˆì—­ ì‚¬ìš©ëŸ‰ ì¶”ì 
        self.gpt_translation_count = 0
        self.claude_translation_count = 0
        self.claude_error_count = 0
        self.last_translation_reset = datetime.now()
        self.max_gpt_translations_per_15min = 30
        self.max_claude_translations_per_15min = 15
        self.translation_reset_interval = 900  # 15ë¶„
        self.claude_cooldown_until = None
        self.claude_cooldown_duration = 300  # 5ë¶„ ì¿¨ë‹¤ìš´
        
        # ìš”ì•½ ì‚¬ìš©ëŸ‰ ì¶”ì 
        self.summary_count = 0
        self.max_summaries_per_15min = 20
        self.last_summary_reset = datetime.now()
        
        # ë²ˆì—­ ìºì‹œ
        self.translation_cache = {}
        
        logger.info(f"ğŸ§  GPT API: {'í™œì„±í™”' if self.openai_client else 'ë¹„í™œì„±í™”'} (ì£¼ë ¥)")
        logger.info(f"ğŸ¤– Claude API: {'í™œì„±í™”' if self.anthropic_client else 'ë¹„í™œì„±í™”'} (ë°±ì—…)")
        logger.info(f"ğŸ’° ë²ˆì—­ ì •ì±…: í¬ë¦¬í‹°ì»¬ ë¦¬í¬íŠ¸ ì „ì†¡ ì‹œì—ë§Œ")
    
    def _reset_translation_count_if_needed(self):
        """í•„ìš”ì‹œ ë²ˆì—­ ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
        now = datetime.now()
        if (now - self.last_translation_reset).total_seconds() > self.translation_reset_interval:
            old_claude_count = self.claude_translation_count
            old_gpt_count = self.gpt_translation_count
            old_error_count = self.claude_error_count
            self.claude_translation_count = 0
            self.gpt_translation_count = 0
            self.claude_error_count = 0
            self.last_translation_reset = now
            
            # Claude ì¿¨ë‹¤ìš´ í•´ì œ
            if self.claude_cooldown_until and now > self.claude_cooldown_until:
                self.claude_cooldown_until = None
                logger.info("âœ… Claude ì¿¨ë‹¤ìš´ í•´ì œ")
            
            if old_claude_count > 0 or old_gpt_count > 0:
                logger.info(f"ğŸ”„ ë²ˆì—­ ì¹´ìš´íŠ¸ ë¦¬ì…‹: GPT {old_gpt_count} â†’ 0, Claude {old_claude_count} â†’ 0, ì—ëŸ¬ {old_error_count} â†’ 0")
    
    def _reset_summary_count_if_needed(self):
        """í•„ìš”ì‹œ ìš”ì•½ ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
        now = datetime.now()
        if (now - self.last_summary_reset).total_seconds() > self.translation_reset_interval:
            old_count = self.summary_count
            self.summary_count = 0
            self.last_summary_reset = now
            if old_count > 0:
                logger.info(f"ğŸ”„ ìš”ì•½ ì¹´ìš´íŠ¸ ë¦¬ì…‹: {old_count} â†’ 0")
    
    def should_translate_for_emergency_report(self, article: Dict) -> bool:
        """ğŸ”¥ğŸ”¥ ê¸´ê¸‰ ë¦¬í¬íŠ¸ ì „ì†¡ ì‹œì—ë§Œ ë²ˆì—­ (API ë¹„ìš© ìµœì†Œí™”)"""
        # ì´ë¯¸ í•œê¸€ ì œëª©ì´ ìˆìœ¼ë©´ ë²ˆì—­ ë¶ˆí•„ìš”
        if article.get('title_ko') and article['title_ko'] != article.get('title', ''):
            return False
        
        # ë²ˆì—­ í•œë„ ì²´í¬
        self._reset_translation_count_if_needed()
        
        # ë²ˆì—­ì´ ê°€ëŠ¥í•œ ìƒíƒœì¸ì§€ í™•ì¸
        can_use_gpt = self.openai_client and self.gpt_translation_count < self.max_gpt_translations_per_15min
        can_use_claude = self._is_claude_available()
        
        if not (can_use_gpt or can_use_claude):
            logger.warning(f"âš ï¸ ë²ˆì—­ í•œë„ ì´ˆê³¼ - GPT: {self.gpt_translation_count}/{self.max_gpt_translations_per_15min}, Claude: {self.claude_translation_count}/{self.max_claude_translations_per_15min}")
            return False
        
        return True
    
    def _is_claude_available(self) -> bool:
        """Claude API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        if not self.anthropic_client:
            return False
        
        # ì¿¨ë‹¤ìš´ ì¤‘ì¸ì§€ í™•ì¸
        if self.claude_cooldown_until and datetime.now() < self.claude_cooldown_until:
            return False
        
        # ë²ˆì—­ ì¹´ìš´íŠ¸ ë¦¬ì…‹ ì²´í¬
        self._reset_translation_count_if_needed()
        
        # Rate limit ì²´í¬
        if self.claude_translation_count >= self.max_claude_translations_per_15min:
            return False
        
        # ì—ëŸ¬ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì¼ì‹œ ì¤‘ë‹¨
        if self.claude_error_count >= 2:
            self.claude_cooldown_until = datetime.now() + timedelta(seconds=self.claude_cooldown_duration)
            logger.warning(f"âš ï¸ Claude API ì—ëŸ¬ê°€ {self.claude_error_count}íšŒ ë°œìƒ, {self.claude_cooldown_duration//60}ë¶„ ì¿¨ë‹¤ìš´ ì‹œì‘")
            return False
        
        return True
    
    async def translate_with_gpt(self, text: str, max_length: int = 400) -> str:
        """ğŸ”¥ğŸ”¥ GPT APIë¥¼ ì‚¬ìš©í•œ ë²ˆì—­ - ì£¼ë ¥ ì‚¬ìš©"""
        if not self.openai_client:
            logger.warning("âš ï¸ GPT API í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
            return text
        
        # ë²ˆì—­ ì¹´ìš´íŠ¸ ë¦¬ì…‹ ì²´í¬
        self._reset_translation_count_if_needed()
        
        # GPT Rate limit ì²´í¬
        if self.gpt_translation_count >= self.max_gpt_translations_per_15min:
            logger.warning(f"âš ï¸ GPT ë²ˆì—­ í•œë„ ì´ˆê³¼: {self.gpt_translation_count}/{self.max_gpt_translations_per_15min}")
            return text
        
        # ìºì‹œ í™•ì¸
        cache_key = f"gpt_{hashlib.md5(text.encode()).hexdigest()}"
        if cache_key in self.translation_cache:
            logger.debug(f"ğŸ”„ GPT ë²ˆì—­ ìºì‹œ íˆíŠ¸")
            return self.translation_cache[cache_key]
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë¹„íŠ¸ì½”ì¸ ì „ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. ì˜ë¬¸ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”."},
                    {"role": "user", "content": f"ë‹¤ìŒì„ í•œêµ­ì–´ë¡œ ë²ˆì—­ (ìµœëŒ€ {max_length}ì):\n\n{text}"}
                ],
                max_tokens=150,
                temperature=0.2,
                timeout=15.0
            )
            
            translated = response.choices[0].message.content.strip()
            
            # ê¸¸ì´ ì²´í¬
            if len(translated) > max_length:
                translated = translated[:max_length-3] + "..."
            
            # ìºì‹œ ì €ì¥
            self.translation_cache[cache_key] = translated
            
            # ìºì‹œ í¬ê¸° ì œí•œ
            if len(self.translation_cache) > 500:
                keys_to_remove = list(self.translation_cache.keys())[:250]
                for key in keys_to_remove:
                    del self.translation_cache[key]
            
            self.gpt_translation_count += 1
            logger.info(f"ğŸ§  GPT ë²ˆì—­ ì™„ë£Œ ({self.gpt_translation_count}/{self.max_gpt_translations_per_15min}) - í¬ë¦¬í‹°ì»¬ ì „ìš©")
            return translated
            
        except Exception as e:
            logger.warning(f"âŒ GPT ë²ˆì—­ ì‹¤íŒ¨: {str(e)[:50]}")
            return text
    
    async def translate_with_claude(self, text: str, max_length: int = 400) -> str:
        """ğŸ”¥ğŸ”¥ Claude APIë¥¼ ì‚¬ìš©í•œ ë²ˆì—­ - ì—ëŸ¬ ì²˜ë¦¬ ê°•í™” (ë°±ì—…ìš©)"""
        if not self._is_claude_available():
            return ""  # ë¹ˆ ë¬¸ìì—´ ë°˜í™˜í•˜ì—¬ GPTë¡œ ë„˜ì–´ê°€ë„ë¡
        
        # ìºì‹œ í™•ì¸
        cache_key = f"claude_{hashlib.md5(text.encode()).hexdigest()}"
        if cache_key in self.translation_cache:
            logger.debug(f"ğŸ”„ Claude ë²ˆì—­ ìºì‹œ íˆíŠ¸")
            return self.translation_cache[cache_key]
        
        try:
            response = await self.anthropic_client.messages.create(
                model="claude-3-5-haiku-20241022",  # ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸
                max_tokens=200,
                timeout=10.0,
                messages=[{
                    "role": "user", 
                    "content": f"""ë‹¤ìŒ ì˜ë¬¸ ë‰´ìŠ¤ ì œëª©ì„ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ì „ë¬¸ ìš©ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë²ˆì—­í•˜ì„¸ìš”:

- Bitcoin/BTC â†’ ë¹„íŠ¸ì½”ì¸
- ETF â†’ ETF
- Tesla â†’ í…ŒìŠ¬ë¼
- MicroStrategy â†’ ë§ˆì´í¬ë¡œìŠ¤íŠ¸ë˜í‹°ì§€
- SEC â†’ SEC
- Fed/Federal Reserve â†’ ì—°ì¤€
- Trump â†’ íŠ¸ëŸ¼í”„
- China â†’ ì¤‘êµ­
- Russia â†’ ëŸ¬ì‹œì•„
- tariffs â†’ ê´€ì„¸

ìµœëŒ€ {max_length}ì ì´ë‚´ë¡œ ë²ˆì—­í•˜ë˜, ì˜ë¯¸ê°€ ëª…í™•í•˜ê²Œ ì „ë‹¬ë˜ë„ë¡ í•´ì£¼ì„¸ìš”.

ì œëª©: {text}"""
                }]
            )
            
            translated = response.content[0].text.strip()
            
            # ê¸¸ì´ ì²´í¬
            if len(translated) > max_length:
                sentences = translated.split('.')
                result = ""
                for sentence in sentences:
                    if len(result + sentence + ".") <= max_length - 3:
                        result += sentence + "."
                    else:
                        break
                translated = result.strip()
                if not translated:
                    translated = translated[:max_length-3] + "..."
            
            # ìºì‹œ ì €ì¥ ë° ì¹´ìš´íŠ¸ ì¦ê°€
            self.translation_cache[cache_key] = translated
            self.claude_translation_count += 1
            
            logger.info(f"ğŸ¤– Claude ë²ˆì—­ ì™„ë£Œ ({self.claude_translation_count}/{self.max_claude_translations_per_15min}) - í¬ë¦¬í‹°ì»¬ ì „ìš©")
            return translated
            
        except Exception as e:
            # ì—ëŸ¬ ì¹´ìš´íŠ¸ ì¦ê°€
            self.claude_error_count += 1
            error_str = str(e)
            
            # 529 ì—ëŸ¬ (rate limit) íŠ¹ë³„ ì²˜ë¦¬
            if "529" in error_str or "rate" in error_str.lower() or "limit" in error_str.lower():
                logger.warning(f"âš ï¸ Claude API rate limit ê°ì§€ (ì—ëŸ¬ {self.claude_error_count}/2), 30ë¶„ ì¿¨ë‹¤ìš´")
                self.claude_cooldown_until = datetime.now() + timedelta(minutes=30)
            else:
                logger.warning(f"âŒ Claude ë²ˆì—­ ì‹¤íŒ¨ (ì—ëŸ¬ {self.claude_error_count}/2): {error_str[:50]}")
            
            return ""  # ë¹ˆ ë¬¸ìì—´ ë°˜í™˜í•˜ì—¬ GPTë¡œ ë„˜ì–´ê°€ë„ë¡
    
    async def translate_text(self, text: str, max_length: int = 400) -> str:
        """ğŸ”¥ğŸ”¥ í†µí•© ë²ˆì—­ í•¨ìˆ˜ - GPT ìš°ì„ , Claude ë°±ì—…"""
        # 1ìˆœìœ„: GPT (ì•ˆì •ì )
        if self.openai_client:
            result = await self.translate_with_gpt(text, max_length)
            if result != text:  # ë²ˆì—­ì´ ì„±ê³µí–ˆìœ¼ë©´
                return result
        
        # 2ìˆœìœ„: Claude (ë³´ì¡°ìš©)
        if self._is_claude_available():
            result = await self.translate_with_claude(text, max_length)
            if result:  # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´
                return result
        
        # ëª¨ë“  ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ë°˜í™˜
        logger.warning(f"âš ï¸ ëª¨ë“  ë²ˆì—­ ì‹¤íŒ¨, ì›ë¬¸ ë°˜í™˜: {text[:50]}...")
        return text
    
    def should_use_gpt_summary(self, article: Dict) -> bool:
        """ğŸ”¥ğŸ”¥ GPT ìš”ì•½ ì‚¬ìš© ì—¬ë¶€ ê²°ì • - í¬ë¦¬í‹°ì»¬ ë¦¬í¬íŠ¸ë§Œ"""
        # ìš”ì•½ ì¹´ìš´íŠ¸ ë¦¬ì…‹ ì²´í¬
        self._reset_summary_count_if_needed()
        
        # Rate limit ì²´í¬
        if self.summary_count >= self.max_summaries_per_15min:
            return False
        
        # descriptionì´ ì¶©ë¶„íˆ ê¸¸ì–´ì•¼ í•¨ (ìš”ì•½í•  ê°€ì¹˜ê°€ ìˆì–´ì•¼ í•¨)
        description = article.get('description', '')
        if len(description) < 200:
            return False
        
        return True
    
    async def summarize_article(self, title: str, description: str, max_length: int = 200) -> str:
        """ğŸ”¥ğŸ”¥ ê°œì„ ëœ ìš”ì•½ - ê¸°ë³¸ ìš”ì•½ ìš°ì„ , GPTëŠ” ë°±ì—…"""
        
        # ğŸ”¥ğŸ”¥ ë¨¼ì € ê¸°ë³¸ ìš”ì•½ìœ¼ë¡œ ì‹œë„
        basic_summary = self._generate_basic_summary(title, description)
        if basic_summary and len(basic_summary.strip()) > 50:
            logger.debug(f"ğŸ”„ ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©")
            return basic_summary
        
        # GPT ìš”ì•½ì´ ì •ë§ í•„ìš”í•œ ê²½ìš°ë§Œ
        if not self.openai_client or not description:
            return basic_summary or "ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ë°œí‘œê°€ ìˆì—ˆë‹¤. íˆ¬ììë“¤ì€ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•˜ë‹¤."
        
        if len(description) <= 200:
            return basic_summary or self._generate_basic_summary(title, description)
        
        # ìš”ì•½ ì¹´ìš´íŠ¸ ë¦¬ì…‹ ì²´í¬
        self._reset_summary_count_if_needed()
        
        # Rate limit ì²´í¬
        if self.summary_count >= self.max_summaries_per_15min:
            logger.warning(f"âš ï¸ ìš”ì•½ í•œë„ ì´ˆê³¼: {self.summary_count}/{self.max_summaries_per_15min} - ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©")
            return basic_summary or "ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ë°œí‘œê°€ ìˆì—ˆë‹¤. íˆ¬ììë“¤ì€ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•˜ë‹¤."
        
        try:
            news_type = self._classify_news_for_summary(title, description)
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"ë¹„íŠ¸ì½”ì¸ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ì •í™•í•˜ê³  ê°ê´€ì ìœ¼ë¡œ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n\n1ë¬¸ì¥: í•µì‹¬ ì‚¬ì‹¤\n2ë¬¸ì¥: ì¤‘ìš”ì„±/ë°°ê²½\n3ë¬¸ì¥: ì‹œì¥ ì˜í–¥\n\në‰´ìŠ¤ íƒ€ì…: {news_type}"},
                    {"role": "user", "content": f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ ì •í™•íˆ 3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš” (ìµœëŒ€ {max_length}ì):\n\nì œëª©: {title}\n\në‚´ìš©: {description[:800]}"}
                ],
                max_tokens=250,
                temperature=0.1,
                timeout=15.0
            )
            
            summary = response.choices[0].message.content.strip()
            
            # 3ë¬¸ì¥ìœ¼ë¡œ ì œí•œ
            sentences = summary.split('.')
            if len(sentences) > 3:
                summary = '. '.join(sentences[:3]) + '.'
            
            if len(summary) > max_length:
                summary = summary[:max_length-3] + "..."
            
            self.summary_count += 1
            logger.info(f"ğŸ“ GPT ìš”ì•½ ì™„ë£Œ ({self.summary_count}/{self.max_summaries_per_15min})")
            
            return summary
            
        except Exception as e:
            logger.warning(f"âŒ GPT ìš”ì•½ ì‹¤íŒ¨: {str(e)[:50]} - ê¸°ë³¸ ìš”ì•½ ì‚¬ìš©")
            return basic_summary or "ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ë°œí‘œê°€ ìˆì—ˆë‹¤. íˆ¬ììë“¤ì€ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•˜ë‹¤."
    
    def _classify_news_for_summary(self, title: str, description: str) -> str:
        """ë‰´ìŠ¤ íƒ€ì… ë¶„ë¥˜"""
        content = (title + " " + description).lower()
        
        if any(word in content for word in ['ai predicts', 'energy crisis', 'boom']):
            return 'ai_prediction'
        elif any(word in content for word in ['crosses', '100k', 'milestone']) and 'bitcoin' in content:
            return 'price_milestone'
        elif any(word in content for word in ['etf approved', 'etf rejected', 'etf filing']):
            return 'etf'
        elif any(word in content for word in ['fed rate', 'fomc', 'powell', 'interest rate']):
            return 'fed_policy'
        elif any(word in content for word in ['inflation', 'cpi', 'pce', 'unemployment']):
            return 'economic_data'
        elif any(company in content for company in ['tesla', 'microstrategy', 'blackrock']):
            return 'corporate_action'
        elif any(word in content for word in ['sec', 'regulation', 'ban', 'lawsuit']):
            return 'regulation'
        elif any(word in content for word in ['tariff', 'trade war', 'trade deal']):
            return 'trade_policy'
        elif any(word in content for word in ['hack', 'stolen', 'breach', 'security']):
            return 'security_incident'
        elif any(word in content for word in ['war', 'conflict', 'sanctions', 'geopolitical']):
            return 'geopolitical'
        else:
            return 'general'
    
    def _generate_basic_summary(self, title: str, description: str) -> str:
        """ğŸ”¥ğŸ”¥ ê°•í™”ëœ ê¸°ë³¸ ìš”ì•½ ìƒì„± - GPT ëŒ€ì‹  ì‚¬ìš©í•  ê³ í’ˆì§ˆ ìš”ì•½"""
        try:
            content = (title + " " + description).lower()
            summary_parts = []
            
            # AI ì˜ˆì¸¡ ê´€ë ¨ íŠ¹ë³„ ì²˜ë¦¬
            if any(word in content for word in ['ai based', 'ai predicts', 'energy crisis']) and 'bitcoin' in content:
                if 'energy crisis' in content and '250000' in content:
                    summary_parts.append("AI ê¸°ë°˜ ì˜ˆì¸¡ì— ë”°ë¥´ë©´ ì—ë„ˆì§€ ìœ„ê¸°ê°€ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì„ 25ë§Œ ë‹¬ëŸ¬ê¹Œì§€ ìƒìŠ¹ì‹œí‚¬ ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.")
                    summary_parts.append("í•˜ì§€ë§Œ ì´ëŠ” ì¶”ì¸¡ì„± ì˜ˆì¸¡ì— ë¶ˆê³¼í•˜ë©° ì‹¤ì œ ì‹œì¥ ìš”ì¸ë“¤ê³¼ëŠ” ê±°ë¦¬ê°€ ìˆì„ ìˆ˜ ìˆë‹¤.")
                    summary_parts.append("íˆ¬ììë“¤ì€ ì´ëŸ° ì˜ˆì¸¡ë³´ë‹¤ëŠ” ì‹¤ì œ ì‹œì¥ ë™í–¥ê³¼ í€ë”ë©˜í„¸ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤.")
                else:
                    summary_parts.append("AI ê¸°ë°˜ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì˜ˆì¸¡ì´ ë°œí‘œë˜ì—ˆë‹¤.")
                    summary_parts.append("ì˜ˆì¸¡ ëª¨ë¸ì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ë„ëŠ” ê²€ì¦ì´ í•„ìš”í•œ ìƒí™©ì´ë‹¤.")
                    summary_parts.append("ì‹œì¥ì€ ì´ëŸ° ì˜ˆì¸¡ë³´ë‹¤ëŠ” ì‹¤ì œ ìˆ˜ê¸‰ê³¼ ê·œì œ ë™í–¥ì— ë” ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•œë‹¤.")
                
                return " ".join(summary_parts)
            
            # ë¹„íŠ¸ì½”ì¸ ê°€ê²© ê´€ë ¨ íŠ¹ë³„ ì²˜ë¦¬
            if any(word in content for word in ['crosses', '100k', '$100', 'milestone']) and 'bitcoin' in content:
                if any(word in content for word in ['search', 'google', 'interest', 'attention']):
                    summary_parts.append("ë¹„íŠ¸ì½”ì¸ì´ 10ë§Œ ë‹¬ëŸ¬ë¥¼ ëŒíŒŒí–ˆì§€ë§Œ êµ¬ê¸€ ê²€ìƒ‰ëŸ‰ì€ ì˜ˆìƒë³´ë‹¤ ë‚®ì€ ìˆ˜ì¤€ì„ ë³´ì´ê³  ìˆë‹¤.")
                    summary_parts.append("ì´ëŠ” ê¸°ê´€ íˆ¬ìì ì¤‘ì‹¬ì˜ ìƒìŠ¹ìœ¼ë¡œ ì¼ë°˜ íˆ¬ììë“¤ì˜ ê´€ì‹¬ì€ ì•„ì§ ì œí•œì ì„ì„ ì‹œì‚¬í•œë‹¤.")
                    summary_parts.append("í–¥í›„ ì†Œë§¤ íˆ¬ììë“¤ì˜ FOMOê°€ ë³¸ê²©í™”ë  ê²½ìš° ì¶”ê°€ ìƒìŠ¹ ì—¬ë ¥ì´ ìˆì„ ê²ƒìœ¼ë¡œ ë¶„ì„ëœë‹¤.")
                else:
                    summary_parts.append("ë¹„íŠ¸ì½”ì¸ì´ 10ë§Œ ë‹¬ëŸ¬ ì´ì •í‘œë¥¼ ëŒíŒŒí•˜ë©° ì—­ì‚¬ì ì¸ ìˆœê°„ì„ ê¸°ë¡í–ˆë‹¤.")
                    summary_parts.append("ì‹¬ë¦¬ì  ì €í•­ì„  ëŒíŒŒë¡œ ë‹¨ê¸°ì ì¸ ìƒìŠ¹ ëª¨ë©˜í…€ì´ í˜•ì„±ë  ìˆ˜ ìˆë‹¤.")
                    summary_parts.append("í•˜ì§€ë§Œ ê³¼ì—´ êµ¬ê°„ì—ì„œëŠ” ìˆ˜ìµ ì‹¤í˜„ ì••ë°•ë„ ë™ì‹œì— ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.")
                
                return " ".join(summary_parts)
            
            # êµ¬ì¡°í™” ìƒí’ˆ íŠ¹ë³„ ì²˜ë¦¬
            if any(word in content for word in ['structured', 'bonds', 'linked', 'exposure']):
                if 'sberbank' in content:
                    summary_parts.append("ëŸ¬ì‹œì•„ ìµœëŒ€ ì€í–‰ ìŠ¤ë² ë¥´ë°©í¬ê°€ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì— ì—°ë™ëœ êµ¬ì¡°í™” ì±„ê¶Œì„ ì¶œì‹œí–ˆë‹¤.")
                    summary_parts.append("ì´ëŠ” ì§ì ‘ì ì¸ ë¹„íŠ¸ì½”ì¸ ë§¤ìˆ˜ê°€ ì•„ë‹Œ ê°€ê²© ì¶”ì  ìƒí’ˆìœ¼ë¡œ, ì‹¤ì œ BTC ìˆ˜ìš” ì°½ì¶œ íš¨ê³¼ëŠ” ì œí•œì ì´ë‹¤.")
                    summary_parts.append("ëŸ¬ì‹œì•„ ì œì¬ ìƒí™©ê³¼ OTC ê±°ë˜ë¡œ ì¸í•´ ê¸€ë¡œë²Œ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì¦‰ê°ì  ì˜í–¥ì€ ë¯¸ë¯¸í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.")
                else:
                    summary_parts.append("ìƒˆë¡œìš´ ë¹„íŠ¸ì½”ì¸ ì—°ê³„ êµ¬ì¡°í™” ìƒí’ˆì´ ì¶œì‹œë˜ì—ˆë‹¤.")
                    summary_parts.append("ì§ì ‘ì ì¸ ë¹„íŠ¸ì½”ì¸ ìˆ˜ìš”ë³´ë‹¤ëŠ” ê°„ì ‘ì  ë…¸ì¶œ ì œê³µì— ì¤‘ì ì„ ë‘” ìƒí’ˆìœ¼ë¡œ í‰ê°€ëœë‹¤.")
                    summary_parts.append("ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì‹¤ì§ˆì  ì˜í–¥ì€ ì œí•œì ì¼ ê²ƒìœ¼ë¡œ ì „ë§ëœë‹¤.")
                
                return " ".join(summary_parts)
            
            # ETF ê´€ë ¨
            if 'etf' in content:
                if 'approved' in content or 'approval' in content:
                    summary_parts.append("ë¹„íŠ¸ì½”ì¸ í˜„ë¬¼ ETF ìŠ¹ì¸ ì†Œì‹ì´ ì „í•´ì¡Œë‹¤.")
                    summary_parts.append("ETF ìŠ¹ì¸ì€ ê¸°ê´€ íˆ¬ììë“¤ì˜ ëŒ€ê·œëª¨ ìê¸ˆ ìœ ì…ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì¤‘ìš”í•œ ì´ì •í‘œë‹¤.")
                    summary_parts.append("ë¹„íŠ¸ì½”ì¸ ì‹œì¥ì˜ ì„±ìˆ™ë„ì™€ ì œë„ì  ì¸ì •ì„ ë³´ì—¬ì£¼ëŠ” ìƒì§•ì  ì‚¬ê±´ìœ¼ë¡œ í‰ê°€ëœë‹¤.")
                elif 'rejected' in content or 'delay' in content:
                    summary_parts.append("ë¹„íŠ¸ì½”ì¸ ETF ìŠ¹ì¸ì´ ì§€ì—°ë˜ê±°ë‚˜ ê±°ë¶€ë˜ì—ˆë‹¤.")
                    summary_parts.append("ë‹¨ê¸°ì  ì‹¤ë§ê°ì€ ìˆìœ¼ë‚˜, ì§€ì†ì ì¸ ì‹ ì²­ì€ ê²°êµ­ ìŠ¹ì¸ ê°€ëŠ¥ì„±ì„ ë†’ì´ê³  ìˆë‹¤.")
                    summary_parts.append("ì‹œì¥ì€ ì´ë¯¸ ETF ìŠ¹ì¸ì„ ê¸°ì •ì‚¬ì‹¤ë¡œ ë°›ì•„ë“¤ì´ê³  ìˆì–´ ì¥ê¸° ì „ë§ì€ ê¸ì •ì ì´ë‹¤.")
            
            # ê¸°ë³¸ ì¼€ì´ìŠ¤
            if not summary_parts:
                summary_parts.append("ë¹„íŠ¸ì½”ì¸ ì‹œì¥ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ë°œí‘œê°€ ìˆì—ˆë‹¤.")
                summary_parts.append("íˆ¬ììë“¤ì€ ì´ë²ˆ ì†Œì‹ì˜ ì‹¤ì œ ì‹œì¥ ì˜í–¥ì„ ë©´ë°€íˆ ë¶„ì„í•˜ê³  ìˆë‹¤.")
                summary_parts.append("ë‹¨ê¸° ë³€ë™ì„±ì€ ìˆê² ì§€ë§Œ ì¥ê¸° íŠ¸ë Œë“œì—ëŠ” í° ë³€í™”ê°€ ì—†ì„ ê²ƒìœ¼ë¡œ ì „ë§ëœë‹¤.")
            
            return " ".join(summary_parts[:3]) if summary_parts else "ë¹„íŠ¸ì½”ì¸ ê´€ë ¨ ì†Œì‹ì´ ë°œí‘œë˜ì—ˆë‹¤. ì‹¤ì œ ì˜í–¥ì„ ë¶„ì„í•´ì•¼ í•œë‹¤. íˆ¬ììë“¤ì€ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•˜ë‹¤."
            
        except Exception as e:
            logger.error(f"âŒ ê¸°ë³¸ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ë¹„íŠ¸ì½”ì¸ ì‹œì¥ ê´€ë ¨ ì†Œì‹ì´ ë°œí‘œë˜ì—ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ í™•ì¸í•˜ì‹œê¸° ë°”ë€ë‹¤. ì‹¤ì œ ì‹œì¥ ë°˜ì‘ì„ ë©´ë°€íˆ ë¶„ì„í•  í•„ìš”ê°€ ìˆë‹¤."
    
    def get_translation_stats(self) -> Dict:
        """ë²ˆì—­ í†µê³„ ë°˜í™˜"""
        return {
            'gpt_translations': self.gpt_translation_count,
            'claude_translations': self.claude_translation_count,
            'claude_errors': self.claude_error_count,
            'summaries': self.summary_count,
            'cache_size': len(self.translation_cache),
            'claude_available': self._is_claude_available()
        }
