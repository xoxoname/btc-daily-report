import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set
import hashlib
import re
import json
import os

logger = logging.getLogger(__name__)

class NewsProcessor:
    """ë‰´ìŠ¤ ë¶„ì„, ë¶„ë¥˜, ì¤‘ë³µ ì²´í¬, ì´ë²¤íŠ¸ ìƒì„± ì „ë‹´"""
    
    def __init__(self, config):
        self.config = config
        
        # ì¤‘ìš” ê¸°ì—… ë¦¬ìŠ¤íŠ¸
        self.important_companies = [
            'tesla', 'microstrategy', 'square', 'block', 'paypal', 'mastercard', 'visa',
            'gamestop', 'gme', 'blackrock', 'fidelity', 'ark invest', 'grayscale',
            'coinbase', 'binance', 'kraken', 'bitget', 'okx', 'bybit',
            'metaplanet', 'ë©”íƒ€í”Œë˜ë‹›', 'í…ŒìŠ¬ë¼', 'ë§ˆì´í¬ë¡œìŠ¤íŠ¸ë˜í‹°ì§€',
            'sberbank', 'ìŠ¤ë² ë¥´ë°©í¬', 'jpmorgan', 'goldman sachs', 'morgan stanley',
            'nvidia', 'amd', 'intel', 'apple', 'microsoft', 'amazon',
            'ì‚¼ì„±', 'samsung', 'lg', 'sk', 'hyundai'
        ]
        
        # í¬ë¦¬í‹°ì»¬ í‚¤ì›Œë“œ
        self.critical_keywords = [
            # ë¹„íŠ¸ì½”ì¸ ETF ê´€ë ¨ (ìµœìš°ì„ )
            'bitcoin etf approved', 'bitcoin etf rejected', 'spot bitcoin etf', 'etf decision',
            'blackrock bitcoin etf', 'fidelity bitcoin etf', 'ark bitcoin etf', 'grayscale bitcoin etf',
            'SEC ë¹„íŠ¸ì½”ì¸ ETF', 'ETF ìŠ¹ì¸', 'ETF ê±°ë¶€', 'SEC approves bitcoin', 'SEC rejects bitcoin',
            
            # ê¸°ì—… ë¹„íŠ¸ì½”ì¸ êµ¬ë§¤ (ì§ì ‘ì )
            'tesla bought bitcoin', 'microstrategy bought bitcoin', 'bought bitcoin', 'buys bitcoin',
            'gamestop bitcoin purchase', 'metaplanet bitcoin', 'corporate bitcoin purchase',
            'bitcoin acquisition', 'adds bitcoin', 'bitcoin investment', 'purchases bitcoin',
            'ë¹„íŠ¸ì½”ì¸ êµ¬ë§¤', 'ë¹„íŠ¸ì½”ì¸ ë§¤ì…', 'BTC êµ¬ë§¤', 'BTC ë§¤ì…', 'bitcoin holdings',
            
            # êµ­ê°€/ì€í–‰ ì±„íƒ
            'central bank bitcoin', 'russia bitcoin', 'sberbank bitcoin', 'bitcoin bonds',
            'government bitcoin', 'country adopts bitcoin', 'bitcoin legal tender',
            'ì¤‘ì•™ì€í–‰ ë¹„íŠ¸ì½”ì¸', 'ëŸ¬ì‹œì•„ ë¹„íŠ¸ì½”ì¸', 'ë¹„íŠ¸ì½”ì¸ ì±„ê¶Œ', 'el salvador bitcoin',
            'putin bitcoin', 'russia legalize bitcoin', 'china bitcoin ban lifted',
            
            # ë¹„íŠ¸ì½”ì¸ ê·œì œ (ì§ì ‘ì )
            'sec bitcoin lawsuit', 'bitcoin ban', 'bitcoin regulation', 'bitcoin lawsuit',
            'china bans bitcoin', 'government bans bitcoin', 'court bitcoin', 'biden bitcoin',
            'regulatory approval bitcoin', 'regulatory rejection bitcoin', 'trump bitcoin',
            'SEC ë¹„íŠ¸ì½”ì¸', 'ë¹„íŠ¸ì½”ì¸ ê¸ˆì§€', 'ë¹„íŠ¸ì½”ì¸ ê·œì œ', 'coinbase lawsuit',
            
            # ë¹„íŠ¸ì½”ì¸ ì‹œì¥ ê¸‰ë³€ë™
            'bitcoin crash', 'bitcoin surge', 'bitcoin breaks', 'bitcoin plunge',
            'bitcoin all time high', 'bitcoin ath', 'bitcoin tumbles', 'bitcoin soars',
            'ë¹„íŠ¸ì½”ì¸ í­ë½', 'ë¹„íŠ¸ì½”ì¸ ê¸‰ë“±', 'ë¹„íŠ¸ì½”ì¸ ê¸‰ë½', 'bitcoin reaches',
            'bitcoin hits', 'bitcoin falls below', 'bitcoin crosses',
            
            # ê°€ê²© ì´ì •í‘œ ê´€ë ¨
            'bitcoin crosses 100k', 'bitcoin hits 100000', 'bitcoin 100k milestone',
            'bitcoin google search', 'bitcoin interest low', 'bitcoin searches unchanged',
            
            # Fed ê¸ˆë¦¬ ê²°ì • (ë¹„íŠ¸ì½”ì¸ ì˜í–¥)
            'fed rate decision', 'fomc decision', 'powell speech', 'interest rate decision',
            'federal reserve meeting', 'fed minutes', 'inflation report', 'cpi data',
            'ì—°ì¤€ ê¸ˆë¦¬', 'ê¸°ì¤€ê¸ˆë¦¬', 'í†µí™”ì •ì±…', 'jobless claims', 'unemployment rate',
            
            # ê±°ì‹œê²½ì œ ì˜í–¥
            'us economic policy', 'treasury secretary', 'inflation data', 'cpi report',
            'unemployment rate', 'gdp growth', 'recession fears', 'economic stimulus',
            'quantitative easing', 'dollar strength', 'dollar weakness', 'dxy index',
            'ë‹¬ëŸ¬ ê°•ì„¸', 'ë‹¬ëŸ¬ ì•½ì„¸', 'ì¸í”Œë ˆì´ì…˜', 'ê²½ê¸°ì¹¨ì²´', 'china economic data',
            
            # ë¯¸êµ­ ê´€ì„¸ ë° ë¬´ì—­
            'trump tariffs', 'china tariffs', 'trade war', 'trade deal', 'trade agreement',
            'customs duties', 'import tariffs', 'export restrictions', 'trade negotiations',
            'trade talks deadline', 'tariff exemption', 'tariff extension', 'wto ruling',
            'ê´€ì„¸', 'ë¬´ì—­í˜‘ìƒ', 'ë¬´ì—­ì „ìŸ', 'ë¬´ì—­í•©ì˜', 'usmca agreement',
        ]
        
        # ì œì™¸ í‚¤ì›Œë“œ
        self.exclude_keywords = [
            'how to mine', 'ì§‘ì—ì„œ ì±„êµ´', 'mining at home', 'mining tutorial',
            'price prediction tutorial', 'ê°€ê²© ì˜ˆì¸¡ ë°©ë²•', 'technical analysis tutorial',
            'altcoin only', 'ethereum only', 'ripple only', 'cardano only', 'solana only', 
            'dogecoin only', 'shiba only', 'nft only', 'web3 only', 'metaverse only',
            'defi only', 'gamefi only', 'celebrity news', 'entertainment only',
            'sports only', 'weather', 'local news', 'obituary', 'wedding',
            'movie review', 'book review', 'restaurant review', 'travel guide'
        ]
        
        # ì¤‘ë³µ ë°©ì§€ ë°ì´í„°
        self.processed_news_hashes = set()
        self.sent_news_titles = {}
        self.sent_critical_reports = {}
        self.company_news_count = {}
        self.news_first_seen = {}
        
        # íŒŒì¼ ê²½ë¡œ
        self.news_data_file = 'news_duplicates.json'
        self.processed_reports_file = 'processed_critical_reports.json'
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        self._load_duplicate_data()
        self._load_critical_reports()
        
        # í˜„ì‹¤ì ì¸ ë‰´ìŠ¤ ì˜í–¥ íŒ¨í„´
        self.historical_patterns = {
            'etf_approval': {'avg_impact': 3.5, 'duration_hours': 24, 'confidence': 0.95},
            'etf_rejection': {'avg_impact': -2.8, 'duration_hours': 12, 'confidence': 0.9},
            'tesla_purchase': {'avg_impact': 2.2, 'duration_hours': 18, 'confidence': 0.9},
            'microstrategy_purchase': {'avg_impact': 0.7, 'duration_hours': 8, 'confidence': 0.85},
            'price_milestone': {'avg_impact': 0.2, 'duration_hours': 8, 'confidence': 0.6},
            'price_milestone_low_interest': {'avg_impact': 0.1, 'duration_hours': 4, 'confidence': 0.5},
            'ai_prediction': {'avg_impact': 0.05, 'duration_hours': 2, 'confidence': 0.3},
            'energy_crisis_prediction': {'avg_impact': 0.1, 'duration_hours': 4, 'confidence': 0.4},
            'fed_rate_hike': {'avg_impact': -1.2, 'duration_hours': 6, 'confidence': 0.7},
            'fed_rate_cut': {'avg_impact': 1.5, 'duration_hours': 8, 'confidence': 0.75},
            'new_tariffs': {'avg_impact': -0.8, 'duration_hours': 6, 'confidence': 0.65},
            'trade_deal': {'avg_impact': 0.6, 'duration_hours': 8, 'confidence': 0.7},
            'corporate_structured_product': {'avg_impact': 0.05, 'duration_hours': 2, 'confidence': 0.3},
        }
        
        logger.info(f"ğŸ“Š ë‰´ìŠ¤ ì²˜ë¦¬ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ğŸ¯ í¬ë¦¬í‹°ì»¬ í‚¤ì›Œë“œ: {len(self.critical_keywords)}ê°œ")
        logger.info(f"ğŸ¢ ì¶”ì  ê¸°ì—…: {len(self.important_companies)}ê°œ")
        logger.info(f"ğŸ’¾ ì¤‘ë³µ ë°©ì§€: ì²˜ë¦¬ëœ ë‰´ìŠ¤ {len(self.processed_news_hashes)}ê°œ")
    
    def _load_duplicate_data(self):
        """ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.news_data_file):
                with open(self.news_data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                self.processed_news_hashes = set(data.get('processed_news_hashes', []))
                
                # ì‹œê°„ ê¸°ë°˜ ë°ì´í„° ì •ë¦¬
                current_time = datetime.now()
                cutoff_time = current_time - timedelta(hours=12)
                
                # ë‰´ìŠ¤ ì œëª© ìºì‹œ
                title_data = data.get('sent_news_titles', {})
                for title_hash, time_str in title_data.items():
                    try:
                        sent_time = datetime.fromisoformat(time_str)
                        if sent_time > cutoff_time:
                            self.sent_news_titles[title_hash] = sent_time
                    except:
                        continue
                
                # ì²˜ë¦¬ëœ ë‰´ìŠ¤ í•´ì‹œ í¬ê¸° ì œí•œ
                if len(self.processed_news_hashes) > 3000:
                    self.processed_news_hashes = set(list(self.processed_news_hashes)[-1500:])
                
                logger.info(f"âœ… ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ë¡œë“œ: {len(self.processed_news_hashes)}ê°œ")
                
        except Exception as e:
            logger.warning(f"âŒ ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.processed_news_hashes = set()
            self.sent_news_titles = {}
    
    def _load_critical_reports(self):
        """í¬ë¦¬í‹°ì»¬ ë¦¬í¬íŠ¸ ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.processed_reports_file):
                with open(self.processed_reports_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                current_time = datetime.now()
                cutoff_time = current_time - timedelta(hours=4)
                
                for item in data:
                    try:
                        report_time = datetime.fromisoformat(item['time'])
                        if report_time > cutoff_time:
                            self.sent_critical_reports[item['hash']] = report_time
                    except:
                        continue
                
                logger.info(f"âœ… í¬ë¦¬í‹°ì»¬ ë¦¬í¬íŠ¸ ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ë¡œë“œ: {len(self.sent_critical_reports)}ê°œ")
                
        except Exception as e:
            logger.warning(f"âŒ í¬ë¦¬í‹°ì»¬ ë¦¬í¬íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.sent_critical_reports = {}
    
    def _save_duplicate_data(self):
        """ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ì €ì¥"""
        try:
            title_data = {}
            for title_hash, sent_time in self.sent_news_titles.items():
                title_data[title_hash] = sent_time.isoformat()
            
            data = {
                'processed_news_hashes': list(self.processed_news_hashes),
                'sent_news_titles': title_data,
                'last_updated': datetime.now().isoformat()
            }
            
            with open(self.news_data_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"âŒ ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _save_critical_reports(self):
        """í¬ë¦¬í‹°ì»¬ ë¦¬í¬íŠ¸ ì¤‘ë³µ ë°©ì§€ ë°ì´í„° ì €ì¥"""
        try:
            data_to_save = []
            for report_hash, report_time in self.sent_critical_reports.items():
                data_to_save.append({
                    'hash': report_hash,
                    'time': report_time.isoformat()
                })
            
            with open(self.processed_reports_file, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            logger.error(f"âŒ í¬ë¦¬í‹°ì»¬ ë¦¬í¬íŠ¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def is_bitcoin_or_macro_related(self, article: Dict) -> bool:
        """ë¹„íŠ¸ì½”ì¸ ì§ì ‘ ê´€ë ¨ì„± + ê±°ì‹œê²½ì œ ì˜í–¥ ì²´í¬"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        # ì œì™¸ í‚¤ì›Œë“œ ë¨¼ì € ì²´í¬
        for exclude in self.exclude_keywords:
            if exclude.lower() in content:
                return False
        
        # 1. ë¹„íŠ¸ì½”ì¸ ì§ì ‘ ì–¸ê¸‰
        bitcoin_keywords = ['bitcoin', 'btc', 'ë¹„íŠ¸ì½”ì¸', 'bitcoins']
        has_bitcoin = any(keyword in content for keyword in bitcoin_keywords)
        
        if has_bitcoin:
            return True
        
        # 2. ì•”í˜¸í™”í ì¼ë°˜ + ì¤‘ìš” ë‚´ìš©
        crypto_keywords = ['crypto', 'cryptocurrency', 'ì•”í˜¸í™”í', 'cryptocurrencies', 'digital currency']
        has_crypto = any(keyword in content for keyword in crypto_keywords)
        
        if has_crypto:
            important_terms = ['etf', 'sec', 'regulation', 'ban', 'approval', 'court', 'lawsuit', 
                             'bonds', 'russia', 'sberbank', 'institutional', 'adoption']
            if any(term in content for term in important_terms):
                return True
        
        # 3. Fed ê¸ˆë¦¬ ê²°ì •
        fed_keywords = ['fed rate decision', 'fomc decides', 'powell announces', 'federal reserve decision',
                       'interest rate decision', 'fed chair', 'fed meeting', 'monetary policy']
        if any(keyword in content for keyword in fed_keywords):
            return True
        
        # 4. ì¤‘ìš” ê²½ì œ ì§€í‘œ
        economic_keywords = ['inflation data', 'cpi report', 'unemployment rate', 'jobs report',
                           'gdp growth', 'pce index', 'retail sales', 'manufacturing pmi']
        if any(keyword in content for keyword in economic_keywords):
            return True
        
        # 5. ë¯¸êµ­ ê´€ì„¸ ë° ë¬´ì—­
        trade_keywords = ['trump tariffs', 'china tariffs', 'trade war escalation', 'trade deal signed',
                         'trade agreement', 'trade negotiations breakthrough']
        if any(keyword in content for keyword in trade_keywords):
            return True
        
        return False
    
    def is_critical_news(self, article: Dict) -> bool:
        """í¬ë¦¬í‹°ì»¬ ë‰´ìŠ¤ íŒë‹¨"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        # ë¹„íŠ¸ì½”ì¸ + ê±°ì‹œê²½ì œ ê´€ë ¨ì„± ì²´í¬
        if not self.is_bitcoin_or_macro_related(article):
            return False
        
        # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
        for exclude in self.exclude_keywords:
            if exclude.lower() in content:
                return False
        
        # ê°€ì¤‘ì¹˜ ì²´í¬
        if article.get('weight', 0) < 6:
            return False
        
        # í¬ë¦¬í‹°ì»¬ í‚¤ì›Œë“œ ì²´í¬
        for keyword in self.critical_keywords:
            if keyword.lower() in content:
                # ë¶€ì •ì  í•„í„° (ë£¨ë¨¸, ì¶”ì¸¡ ë“±)
                negative_filters = ['rumor', 'speculation', 'unconfirmed', 'fake', 'false', 
                                  'ë£¨ë¨¸', 'ì¶”ì¸¡', 'ë¯¸í™•ì¸', 'alleged', 'reportedly']
                if any(neg in content for neg in negative_filters):
                    continue
                
                logger.info(f"ğŸš¨ í¬ë¦¬í‹°ì»¬ í‚¤ì›Œë“œ ê°ì§€: '{keyword}' - {article.get('title', '')[:50]}...")
                return True
        
        # ì¶”ê°€ í¬ë¦¬í‹°ì»¬ íŒ¨í„´
        critical_patterns = [
            ('bitcoin', 'etf', 'approved'),
            ('bitcoin', 'etf', 'rejected'),  
            ('bitcoin', 'billion', 'bought'),
            ('bitcoin', 'crosses', '100k'),
            ('tesla', 'bitcoin', 'purchase'),
            ('fed', 'rate', 'decision'),
            ('trump', 'announces', 'tariffs'),
        ]
        
        for pattern in critical_patterns:
            if all(word in content for word in pattern):
                logger.info(f"ğŸš¨ í¬ë¦¬í‹°ì»¬ íŒ¨í„´ ê°ì§€: {pattern} - {article.get('title', '')[:50]}...")
                return True
        
        return False
    
    def is_important_news(self, article: Dict) -> bool:
        """ì¤‘ìš” ë‰´ìŠ¤ íŒë‹¨"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        if not self.is_bitcoin_or_macro_related(article):
            return False
        
        for exclude in self.exclude_keywords:
            if exclude.lower() in content:
                return False
        
        weight = article.get('weight', 0)
        category = article.get('category', '')
        
        conditions = [
            category == 'crypto' and weight >= 6,
            category == 'finance' and weight >= 6 and (
                any(word in content for word in ['bitcoin', 'btc', 'crypto']) or
                any(word in content for word in ['fed', 'rate', 'inflation', 'sec', 'tariffs', 'trade'])
            ),
            category == 'api' and weight >= 7,
            any(company.lower() in content for company in self.important_companies) and 
            any(word in content for word in ['bitcoin', 'btc', 'crypto', 'digital', 'blockchain']),
        ]
        
        return any(conditions)
    
    def extract_company_from_content(self, title: str, description: str = "") -> str:
        """ì»¨í…ì¸ ì—ì„œ ê¸°ì—…ëª… ì¶”ì¶œ"""
        content = (title + " " + description).lower()
        
        found_companies = []
        for company in self.important_companies:
            if company.lower() in content:
                for original in self.important_companies:
                    if original.lower() == company.lower():
                        found_companies.append(original)
                        break
        
        if found_companies:
            return found_companies[0]
        
        return ""
    
    def classify_news_type(self, article: Dict) -> str:
        """ë‰´ìŠ¤ íƒ€ì… ë¶„ë¥˜"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        # AI ì˜ˆì¸¡ ê´€ë ¨
        if any(word in content for word in ['ai based', 'ai predicts', 'energy crisis boom']):
            if 'energy crisis' in content and any(word in content for word in ['250000', '25']):
                return 'energy_crisis_prediction'
            else:
                return 'ai_prediction'
        
        # ê°€ê²© ëŒíŒŒ/ì´ì •í‘œ ê´€ë ¨
        if any(word in content for word in ['crosses', '100k', '$100,000', 'milestone', 'breaks', 'hits']):
            if any(word in content for word in ['search', 'google', 'interest', 'attention']):
                return 'price_milestone'
        
        # ETF ê´€ë ¨
        if 'etf' in content:
            if any(word in content for word in ['approved', 'approval', 'launch']):
                return 'etf_approval'
            elif any(word in content for word in ['rejected', 'rejection', 'delay']):
                return 'etf_rejection'
        
        # ê¸°ì—… íˆ¬ì - ì§ì ‘ vs êµ¬ì¡°í™” ìƒí’ˆ êµ¬ë¶„
        if any(company in content for company in ['tesla', 'microstrategy', 'blackrock', 'gamestop']) and \
           any(word in content for word in ['bought', 'purchased', 'buys', 'adds']):
            return 'corporate_purchase_direct'
        
        # êµ¬ì¡°í™” ìƒí’ˆ
        if any(word in content for word in ['structured', 'bonds', 'linked', 'tracking', 'exposure']) and \
           any(word in content for word in ['bitcoin', 'btc']):
            return 'corporate_structured_product'
        
        # ê·œì œ ê´€ë ¨
        if any(word in content for word in ['regulation', 'legal', 'court']) and \
           any(word in content for word in ['positive', 'approved', 'favorable']):
            return 'regulation_positive'
        elif any(word in content for word in ['ban', 'prohibited', 'lawsuit', 'illegal']):
            return 'regulation_negative'
        
        # Fed ê¸ˆë¦¬ ë° ê±°ì‹œê²½ì œ
        if any(word in content for word in ['fed', 'fomc', 'federal reserve', 'interest rate']):
            return 'fed_rate_decision'
        elif any(word in content for word in ['trump', 'tariffs', 'trade war', 'china tariffs']):
            return 'trade_tariffs'
        elif any(word in content for word in ['inflation', 'cpi', 'pce']):
            return 'inflation_data'
        
        else:
            return 'macro_economic_general'
    
    def estimate_price_impact(self, article: Dict) -> str:
        """í˜„ì‹¤ì  ê°€ê²© ì˜í–¥ ì¶”ì •"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        # ê³¼ê±° íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡
        pattern_match = self._match_historical_pattern(content)
        if pattern_match:
            pattern_data = self.historical_patterns[pattern_match]
            impact = pattern_data['avg_impact']
            duration = pattern_data['duration_hours']
            
            if impact > 0:
                min_impact = max(0.05, impact * 0.8)
                max_impact = impact * 1.2
                direction = "ğŸ“ˆ ìƒìŠ¹"
                emoji = "ğŸš€" if impact >= 2.0 else "ğŸ“ˆ"
            else:
                min_impact = max(0.05, abs(impact) * 0.8)
                max_impact = abs(impact) * 1.2
                direction = "ğŸ“‰ í•˜ë½"
                emoji = "ğŸ”»" if abs(impact) >= 2.0 else "ğŸ“‰"
            
            return f"{emoji} {direction} {min_impact:.2f}~{max_impact:.2f}% ({duration}ì‹œê°„ ë‚´)"
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ì„
        return self._estimate_by_keywords(content)
    
    def _match_historical_pattern(self, content: str) -> Optional[str]:
        """ê³¼ê±° íŒ¨í„´ ë§¤ì¹­"""
        patterns = {
            'etf_approval': ['bitcoin', 'etf', 'approved', 'sec'],
            'etf_rejection': ['bitcoin', 'etf', 'rejected', 'denied'],
            'tesla_purchase': ['tesla', 'bitcoin', 'bought', 'purchase'],
            'microstrategy_purchase': ['microstrategy', 'bitcoin', 'acquired', 'buy'],
            'price_milestone': ['bitcoin', 'crosses', '100k', 'milestone'],
            'price_milestone_low_interest': ['bitcoin', '100k', 'search', 'google'],
            'ai_prediction': ['ai', 'predicts', 'bitcoin', 'price'],
            'energy_crisis_prediction': ['energy', 'crisis', 'bitcoin', 'boom'],
            'fed_rate_hike': ['fed', 'raises', 'rate', 'hike'],
            'fed_rate_cut': ['fed', 'cuts', 'rate', 'lower'],
            'new_tariffs': ['trump', 'tariffs', 'china', 'new'],
            'trade_deal': ['trade', 'deal', 'agreement', 'signed'],
            'corporate_structured_product': ['structured', 'bonds', 'bitcoin', 'linked'],
        }
        
        for pattern_name, keywords in patterns.items():
            matches = sum(1 for keyword in keywords if keyword in content)
            if matches >= 2:
                return pattern_name
        
        return None
    
    def _estimate_by_keywords(self, content: str) -> str:
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°€ê²© ì˜í–¥ ì¶”ì •"""
        # AI ì˜ˆì¸¡ ê´€ë ¨
        if any(word in content for word in ['ai based', 'ai predicts', 'energy crisis boom']):
            return 'âš¡ ë³€ë™ Â±0.05~0.15% (2ì‹œê°„ ë‚´)'
        
        # ê°€ê²© ì´ì •í‘œ ê´€ë ¨
        if any(word in content for word in ['bitcoin crosses 100k', 'bitcoin
