# report_generators/exception_report.py
from .base_generator import BaseReportGenerator
from typing import Dict
from datetime import datetime, timedelta
import pytz
import re
import sys
import os
import hashlib
import json

# ML ì˜ˆì¸¡ê¸° ì„í¬íŠ¸
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
try:
    from ml_predictor import MLPredictor
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False

class ExceptionReportGenerator(BaseReportGenerator):
    """ì˜ˆì™¸ ìƒí™© ë¦¬í¬íŠ¸ ì „ë‹´ ìƒì„±ê¸° - í˜„ì‹¤ì  ì‹œì¥ ë°˜ì‘ ë°˜ì˜ + ë‰´ìŠ¤ í›„ ì‹¤ì œ ê°€ê²© ë³€ë™ ì¶”ê°€"""
    
    def __init__(self, config, data_collector, indicator_system, bitget_client=None):
        super().__init__(config, data_collector, indicator_system, bitget_client)
        
        # ML ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
        self.ml_predictor = None
        if ML_AVAILABLE:
            try:
                self.ml_predictor = MLPredictor()
                self.logger.info(f"ML ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.error(f"ML ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ğŸ”¥ğŸ”¥ ë‰´ìŠ¤ ë°œí‘œ ì‹œì  ê¸°ë¡ ì €ì¥ì†Œ - íŒŒì¼ë¡œ ì˜êµ¬ ì €ì¥
        self.news_initial_data = {}
        self.news_data_file = 'news_initial_data.json'
        self.processed_reports = set()  # ì²˜ë¦¬ëœ ë¦¬í¬íŠ¸ í•´ì‹œ
        self.processed_reports_file = 'processed_reports.json'
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        self._load_news_data()
        self._load_processed_reports()
        
        # í˜„ì‹¤ì ì¸ ë‰´ìŠ¤ ë°˜ì‘ íŒ¨í„´ ë°ì´í„° (ì‹¤ì œ ê³¼ê±° ë°ì´í„° ê¸°ë°˜)
        self.news_reaction_patterns = {
            'etf_approval': {
                'immediate': '+1.5~3%',
                'pattern': 'ì¦‰ì‹œ ê¸‰ë“± í›„ 2-4ì‹œê°„ ë‚´ ìˆ˜ìµ ì‹¤í˜„',
                'duration': '12-24ì‹œê°„',
                'strategy': 'ë°œí‘œ ì§í›„ ì§„ì…, ê³¼ì—´ ì‹œ ë¹ ë¥¸ ìµì ˆ',
                'actual_impact': 'high',
                'typical_range': (1.5, 3.0)
            },
            'etf_rejection': {
                'immediate': '-0.8~2%',
                'pattern': 'ì¦‰ì‹œ í•˜ë½ í›„ 6-12ì‹œê°„ ë‚´ íšŒë³µ',
                'duration': '6-12ì‹œê°„',
                'strategy': 'ê¸‰ë½ ì‹œ ë¶„í•  ë§¤ìˆ˜, ë¹ ë¥¸ íšŒë³µ ê¸°ëŒ€',
                'actual_impact': 'medium',
                'typical_range': (-2.0, -0.8)
            },
            'corporate_purchase_direct': {  # ì‹¤ì œ BTC ë§¤ì…
                'immediate': '+0.3~1.2%',
                'pattern': 'ì ì§„ì  ìƒìŠ¹, ë©°ì¹ ê°„ ì§€ì† ê°€ëŠ¥',
                'duration': '1-3ì¼',
                'strategy': 'ë¶„í•  ë§¤ìˆ˜, ì¤‘ê¸° ë³´ìœ  ê³ ë ¤',
                'actual_impact': 'medium',
                'typical_range': (0.3, 1.2)
            },
            'corporate_structured_product': {  # êµ¬ì¡°í™” ìƒí’ˆ (ìŠ¤ë² ë¥´ë°©í¬ íƒ€ì…)
                'immediate': '+0.05~0.2%',
                'pattern': 'ë¯¸ë¯¸í•œ ë°˜ì‘, ìˆ˜ ì‹œê°„ ë‚´ ì†Œë©¸',
                'duration': '2-6ì‹œê°„',
                'strategy': 'ë‹¨ê¸° ìŠ¤ìº˜í•‘ë§Œ ê³ ë ¤, ì¥ê¸° ì˜í–¥ ì—†ìŒ',
                'actual_impact': 'minimal',
                'typical_range': (0.05, 0.2)
            },
            'regulation_positive': {
                'immediate': '+0.3~0.8%',
                'pattern': 'ì´ˆê¸° ìƒìŠ¹ í›„ ì•ˆì •í™”',
                'duration': '6-24ì‹œê°„',
                'strategy': 'ë‹¨ê¸° ìŠ¤ìœ™, ê³¼ì—´ êµ¬ê°„ ì£¼ì˜',
                'actual_impact': 'medium',
                'typical_range': (0.3, 0.8)
            },
            'regulation_negative': {
                'immediate': '-0.8~2.5%',
                'pattern': 'ê¸‰ë½ í›„ ë°˜ë“±, Vì íšŒë³µ íŒ¨í„´',
                'duration': '6-18ì‹œê°„',
                'strategy': 'ê¸‰ë½ ì‹œ ë¶„í•  ë§¤ìˆ˜, ë°˜ë“± íƒ€ì´ë° í¬ì°©',
                'actual_impact': 'medium',
                'typical_range': (-2.5, -0.8)
            },
            'banking_adoption': {
                'immediate': '+0.1~0.5%',
                'pattern': 'ì™„ë§Œí•œ ìƒìŠ¹, ê¸°ê´€ ê´€ì‹¬ ì§€ì†',
                'duration': '1-2ì¼',
                'strategy': 'ì¥ê¸° ê´€ì  ë§¤ìˆ˜, í•˜ë½ ì‹œ ì¶”ê°€ ë§¤ìˆ˜',
                'actual_impact': 'low',
                'typical_range': (0.1, 0.5)
            },
            'hack_incident': {
                'immediate': '-0.3~1.5%',
                'pattern': 'ì¦‰ì‹œ í•˜ë½ í›„ 4-8ì‹œê°„ ë‚´ íšŒë³µ',
                'duration': '4-12ì‹œê°„',
                'strategy': 'ê³µí¬ ë§¤ë„ ì‹œ ì—­ë§¤ë§¤, ë‹¨ê¸° ë°˜ë“± ê¸°ëŒ€',
                'actual_impact': 'low',
                'typical_range': (-1.5, -0.3)
            },
            'fed_rate_decision': {
                'immediate': 'Â±0.8~2%',
                'pattern': 'ë°©í–¥ì„± ëšœë ·, í•˜ë£¨ ë‚´ ì¶”ì„¸ í™•ì •',
                'duration': '12-48ì‹œê°„',
                'strategy': 'ë°©í–¥ì„± í™•ì¸ í›„ ì¶”ì„¸ ì¶”ì¢…',
                'actual_impact': 'high',
                'typical_range': (-2.0, 2.0)
            },
            'trade_tariffs': {  # ìƒˆë¡œ ì¶”ê°€
                'immediate': '-0.3~0.8%',
                'pattern': 'ì¦‰ì‹œ í•˜ë½ í›„ ìˆ˜ ì‹œê°„ ë‚´ ì•ˆì •í™”',
                'duration': '6-12ì‹œê°„',
                'strategy': 'ë‹¨ê¸° í•˜ë½ ì‹œ ë§¤ìˆ˜ ê¸°íšŒ, ì¥ê¸° ì˜í–¥ ì œí•œì ',
                'actual_impact': 'medium',
                'typical_range': (-0.8, -0.3)
            },
            'inflation_data': {  # ìƒˆë¡œ ì¶”ê°€
                'immediate': '+0.2~0.8%',
                'pattern': 'ì¸í”Œë ˆì´ì…˜ í—¤ì§€ ìˆ˜ìš”ë¡œ ì™„ë§Œí•œ ìƒìŠ¹',
                'duration': '12-24ì‹œê°„',
                'strategy': 'í—¤ì§€ ìˆ˜ìš” ì§€ì† ì‹œ ì¶”ê°€ ë§¤ìˆ˜',
                'actual_impact': 'medium',
                'typical_range': (0.2, 0.8)
            },
            'price_milestone': {  # ê°€ê²© ëŒíŒŒ ê´€ë ¨ (ìƒˆë¡œ ì¶”ê°€)
                'immediate': '+0.05~0.3%',
                'pattern': 'ì‹¬ë¦¬ì  ì €í•­ì„  ëŒíŒŒ í›„ ë‹¨ê¸° ìƒìŠ¹',
                'duration': '4-12ì‹œê°„',
                'strategy': 'ëŒíŒŒ í™•ì¸ í›„ ë‹¨ê¸° ì¶”ê²©, ê³¼ì—´ ì£¼ì˜',
                'actual_impact': 'low',
                'typical_range': (0.05, 0.3)
            },
            'ai_prediction': {  # AI ì˜ˆì¸¡ ê´€ë ¨ (ìƒˆë¡œ ì¶”ê°€)
                'immediate': '+0.02~0.1%',
                'pattern': 'ë¯¸ë¯¸í•œ ë°˜ì‘, ì¶”ì¸¡ì„± ì •ë³´',
                'duration': '1-4ì‹œê°„',
                'strategy': 'ë¬´ì‹œí•˜ê±°ë‚˜ ë§¤ìš° ì‹ ì¤‘í•œ ì ‘ê·¼',
                'actual_impact': 'minimal',
                'typical_range': (0.02, 0.1)
            },
            'energy_crisis_prediction': {  # ì—ë„ˆì§€ ìœ„ê¸° ì˜ˆì¸¡ (ìƒˆë¡œ ì¶”ê°€)
                'immediate': '+0.05~0.15%',
                'pattern': 'ê°€ì„¤ì  ì‹œë‚˜ë¦¬ì˜¤, ì œí•œì  ë°˜ì‘',
                'duration': '2-6ì‹œê°„',
                'strategy': 'íˆ¬ê¸°ì  ê±°ë˜ë§Œ ê³ ë ¤, ì¥ê¸° ë¬´ê´€',
                'actual_impact': 'minimal',
                'typical_range': (0.05, 0.15)
            },
            'macro_economic_general': {  # ì¼ë°˜ ê±°ì‹œê²½ì œ
                'immediate': '+0.1~0.4%',
                'pattern': 'ì œí•œì  ë°˜ì‘, ë‹¨ê¸°ê°„ ì˜í–¥',
                'duration': '2-8ì‹œê°„',
                'strategy': 'ì‹ ì¤‘í•œ ê´€ë§',
                'actual_impact': 'low',
                'typical_range': (-0.4, 0.4)
            }
        }
        
        # ì¤‘ìš” ê¸°ì—… ë¦¬ìŠ¤íŠ¸ (ë¹„íŠ¸ì½”ì¸ ë³´ìœ /ê´€ë ¨)
        self.important_companies = [
            'tesla', 'microstrategy', 'square', 'block', 'paypal', 'mastercard',
            'gamestop', 'gme', 'blackrock', 'fidelity', 'ark invest',
            'coinbase', 'binance', 'kraken', 'bitget',
            'metaplanet', 'ë©”íƒ€í”Œë˜ë‹›', 'í…ŒìŠ¬ë¼', 'ë§ˆì´í¬ë¡œìŠ¤íŠ¸ë˜í‹°ì§€',
            'sberbank', 'ìŠ¤ë² ë¥´ë°©í¬', 'jpmorgan', 'goldman sachs'
        ]
    
    def _load_news_data(self):
        """ë‰´ìŠ¤ ì´ˆê¸° ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.news_data_file):
                with open(self.news_data_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜
                for key, value in data.items():
                    if 'time' in value:
                        value['time'] = datetime.fromisoformat(value['time'])
                
                self.news_initial_data = data
                
                # 24ì‹œê°„ ì´ìƒ ëœ ë°ì´í„° ì •ë¦¬
                cutoff_time = datetime.now() - timedelta(hours=24)
                self.news_initial_data = {
                    k: v for k, v in self.news_initial_data.items()
                    if v.get('time', datetime.now()) > cutoff_time
                }
                
                self.logger.info(f"ë‰´ìŠ¤ ì´ˆê¸° ë°ì´í„° ë¡œë“œ: {len(self.news_initial_data)}ê°œ")
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.news_initial_data = {}
    
    def _save_news_data(self):
        """ë‰´ìŠ¤ ì´ˆê¸° ë°ì´í„° ì €ì¥"""
        try:
            # datetimeì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            data_to_save = {}
            for key, value in self.news_initial_data.items():
                new_value = value.copy()
                if 'time' in new_value and isinstance(new_value['time'], datetime):
                    new_value['time'] = new_value['time'].isoformat()
                data_to_save[key] = new_value
            
            with open(self.news_data_file, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ë‰´ìŠ¤ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _load_processed_reports(self):
        """ì²˜ë¦¬ëœ ë¦¬í¬íŠ¸ í•´ì‹œ ë¡œë“œ"""
        try:
            if os.path.exists(self.processed_reports_file):
                with open(self.processed_reports_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # ì‹œê°„ ê¸°ë°˜ í•„í„°ë§ (6ì‹œê°„ ì´ë‚´ë§Œ ìœ ì§€)
                cutoff_time = datetime.now() - timedelta(hours=6)
                
                valid_reports = []
                for item in data:
                    try:
                        report_time = datetime.fromisoformat(item['time'])
                        if report_time > cutoff_time:
                            valid_reports.append(item['hash'])
                    except:
                        continue
                
                self.processed_reports = set(valid_reports)
                self.logger.info(f"ì²˜ë¦¬ëœ ë¦¬í¬íŠ¸ í•´ì‹œ ë¡œë“œ: {len(self.processed_reports)}ê°œ")
        except Exception as e:
            self.logger.error(f"ì²˜ë¦¬ëœ ë¦¬í¬íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.processed_reports = set()
    
    def _save_processed_reports(self):
        """ì²˜ë¦¬ëœ ë¦¬í¬íŠ¸ í•´ì‹œ ì €ì¥"""
        try:
            current_time = datetime.now()
            data_to_save = []
            
            for report_hash in self.processed_reports:
                data_to_save.append({
                    'hash': report_hash,
                    'time': current_time.isoformat()
                })
            
            with open(self.processed_reports_file, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ì²˜ë¦¬ëœ ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _generate_report_hash(self, event: Dict) -> str:
        """ë¦¬í¬íŠ¸ ê³ ìœ  í•´ì‹œ ìƒì„±"""
        if event.get('type') == 'critical_news':
            title = event.get('title', '')
            published_at = event.get('published_at', '')
            
            # ì œëª©ê³¼ ë°œí–‰ì‹œê°„ì„ ì¡°í•©í•œ í•´ì‹œ
            content = f"{title}_{published_at}"
            return hashlib.md5(content.encode()).hexdigest()
        else:
            # ë‹¤ë¥¸ íƒ€ì…ì˜ ì´ë²¤íŠ¸
            content = f"{event.get('type', '')}_{event.get('description', '')}_{datetime.now().strftime('%Y%m%d%H')}"
            return hashlib.md5(content.encode()).hexdigest()
    
    def _is_duplicate_report(self, event: Dict) -> bool:
        """ì¤‘ë³µ ë¦¬í¬íŠ¸ ì²´í¬"""
        report_hash = self._generate_report_hash(event)
        
        if report_hash in self.processed_reports:
            self.logger.info(f"ì¤‘ë³µ ë¦¬í¬íŠ¸ ê°ì§€ - ì „ì†¡ ìƒëµ: {event.get('title', '')[:50]}...")
            return True
        
        # ìƒˆë¡œìš´ ë¦¬í¬íŠ¸ë¡œ ê¸°ë¡
        self.processed_reports.add(report_hash)
        
        # í¬ê¸° ì œí•œ (ìµœëŒ€ 1000ê°œ)
        if len(self.processed_reports) > 1000:
            # ì˜¤ë˜ëœ ê²ƒë¶€í„° ì œê±° (ë‹¨ìˆœí•˜ê²Œ ì¼ë¶€ ì œê±°)
            self.processed_reports = set(list(self.processed_reports)[-500:])
        
        # íŒŒì¼ì— ì €ì¥
        self._save_processed_reports()
        
        return False
    
    def _classify_news_type(self, article: Dict) -> str:
        """ë‰´ìŠ¤ íƒ€ì… ë¶„ë¥˜ - êµ¬ì¡°í™” ìƒí’ˆ vs ì§ì ‘ íˆ¬ì + ê±°ì‹œê²½ì œ êµ¬ë¶„ + AI ì˜ˆì¸¡ ì¶”ê°€"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        # ğŸ”¥ğŸ”¥ AI ì˜ˆì¸¡ ê´€ë ¨ (ìƒˆë¡œ ì¶”ê°€)
        if any(word in content for word in ['ai based', 'ai predicts', 'energy crisis boom']):
            if 'energy crisis' in content and any(word in content for word in ['250000', '25']):
                return 'energy_crisis_prediction'
            else:
                return 'ai_prediction'
        
        # ğŸ”¥ğŸ”¥ ê°€ê²© ëŒíŒŒ/ì´ì •í‘œ ê´€ë ¨ (ìƒˆë¡œ ì¶”ê°€)
        if any(word in content for word in ['crosses', '100k', '$100,000', 'milestone', 'breaks', 'hits']):
            if any(word in content for word in ['search', 'google', 'interest', 'attention']):
                return 'price_milestone'
        
        # ETF ê´€ë ¨
        if 'etf' in content:
            if any(word in content for word in ['approved', 'approval', 'launch']):
                return 'etf_approval'
            elif any(word in content for word in ['rejected', 'rejection', 'delay']):
                return 'etf_rejection'
        
        # ê¸°ì—… íˆ¬ì - ì§ì ‘ vs êµ¬ì¡°í™” ìƒí’ˆ êµ¬ë¶„
        if any(company in content for company in ['tesla', 'microstrategy', 'blackrock', 'gamestop']) and \
           any(word in content for word in ['bought', 'purchased', 'buys', 'adds']):
            return 'corporate_purchase_direct'
        
        # êµ¬ì¡°í™” ìƒí’ˆ (ë¹„íŠ¸ì½”ì¸ ì§ì ‘ ë§¤ìˆ˜ ì•„ë‹˜)
        if any(word in content for word in ['structured', 'bonds', 'linked', 'tracking', 'exposure']) and \
           any(word in content for word in ['bitcoin', 'btc']):
            return 'corporate_structured_product'
        
        # ì€í–‰/ê¸°ê´€ ì±„íƒ
        if any(bank in content for bank in ['sberbank', 'bank', 'central bank']) and \
           any(word in content for word in ['bitcoin', 'btc', 'bonds', 'launches']):
            # êµ¬ì¡°í™” ìƒí’ˆì¸ì§€ ì§ì ‘ íˆ¬ìì¸ì§€ êµ¬ë¶„
            if any(word in content for word in ['structured', 'bonds', 'linked', 'exposure']):
                return 'corporate_structured_product'
            else:
                return 'banking_adoption'
        
        # ê·œì œ ê´€ë ¨
        if any(word in content for word in ['regulation', 'legal', 'court']) and \
           any(word in content for word in ['positive', 'approved', 'favorable']):
            return 'regulation_positive'
        elif any(word in content for word in ['ban', 'prohibited', 'lawsuit', 'illegal']):
            return 'regulation_negative'
        
        # Fed ê¸ˆë¦¬ ë° ê±°ì‹œê²½ì œ
        if any(word in content for word in ['fed', 'fomc', 'federal reserve', 'interest rate']):
            return 'fed_rate_decision'
        elif any(word in content for word in ['trump', 'tariffs', 'trade war', 'china tariffs']):
            return 'trade_tariffs'
        elif any(word in content for word in ['inflation', 'cpi', 'pce']):
            return 'inflation_data'
        
        # í•´í‚¹/ë³´ì•ˆ
        elif any(word in content for word in ['hack', 'stolen', 'breach', 'exploit']):
            return 'hack_incident'
        
        else:
            return 'macro_economic_general'
    
    def _get_ml_impact_prediction(self, article: Dict) -> Dict:
        """ML ê¸°ë°˜ ì˜í–¥ ì˜ˆì¸¡ - í˜„ì‹¤ì  ì¡°ì •"""
        try:
            if not self.ml_predictor:
                return self._get_fallback_prediction(article)
            
            # ë‰´ìŠ¤ íŠ¹ì„± ì¶”ì¶œ
            features = self._extract_news_features(article)
            
            # ML ì˜ˆì¸¡ ì‹¤í–‰
            prediction = self.ml_predictor.predict_price_impact(features)
            
            # í˜„ì‹¤ì  ì¡°ì • (ê³¼ë„í•œ ì˜ˆì¸¡ ë°©ì§€)
            magnitude = min(prediction.get('magnitude', 0.5), 1.5)  # ìµœëŒ€ 1.5% ì œí•œ
            confidence = prediction.get('confidence', 0.6)
            
            return {
                'direction': prediction.get('direction', 'neutral'),
                'magnitude': magnitude,
                'confidence': confidence,
                'timeframe': self._get_realistic_timeframe(article),
                'risk_level': prediction.get('risk_level', 'medium')
            }
            
        except Exception as e:
            self.logger.error(f"ML ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return self._get_fallback_prediction(article)
    
    def _get_realistic_timeframe(self, article: Dict) -> str:
        """í˜„ì‹¤ì ì¸ ë°˜ì‘ ì‹œì  ê³„ì‚°"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        # ì¦‰ì‹œ ë°˜ì‘ (ê³ ì˜í–¥)
        if any(word in content for word in ['etf approved', 'etf rejected', 'fed rate']):
            return 'ì¦‰ì‹œ-30ë¶„'
        
        # ë¹ ë¥¸ ë°˜ì‘ (ì¤‘ì˜í–¥)
        elif any(word in content for word in ['bought billion', 'lawsuit', 'ban']):
            return '30ë¶„-2ì‹œê°„'
        
        # ì§€ì—° ë°˜ì‘ (ì €ì˜í–¥)
        elif any(word in content for word in ['structured', 'bonds', 'linked', 'milestone', 'crosses', 'ai predicts']):
            return '1-4ì‹œê°„ (ë¯¸ë¯¸)'
        
        # ì¼ë°˜
        else:
            return '1-6ì‹œê°„'
    
    def _extract_news_features(self, article: Dict) -> Dict:
        """ë‰´ìŠ¤ì—ì„œ ML íŠ¹ì„± ì¶”ì¶œ"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        features = {
            'has_bitcoin_keyword': any(word in content for word in ['bitcoin', 'btc']),
            'has_amount': bool(re.search(r'\$?\d+(?:,\d+)*(?:\.\d+)?\s*(?:billion|million|thousand)', content)),
            'sentiment_score': self._calculate_sentiment_score(content),
            'source_weight': article.get('weight', 5),
            'company_involved': any(company in content for company in ['tesla', 'microstrategy', 'blackrock']),
            'regulatory_keyword': any(word in content for word in ['sec', 'etf', 'regulation', 'court']),
            'urgency_indicators': len(re.findall(r'breaking|urgent|alert|immediate', content)),
            'negative_keywords': len(re.findall(r'ban|prohibited|hack|stolen|crash|plunge', content)),
            'positive_keywords': len(re.findall(r'approved|launch|bought|partnership|adoption', content)),
            'is_structured_product': any(word in content for word in ['structured', 'bonds', 'linked', 'exposure']),  
            'is_direct_investment': any(word in content for word in ['bought', 'purchased', 'acquired']) and not any(word in content for word in ['structured', 'bonds', 'linked']),
            'is_macro_economic': any(word in content for word in ['fed', 'tariffs', 'inflation', 'trade']),
            'is_price_milestone': any(word in content for word in ['crosses', '100k', 'milestone', 'breaks', 'hits']),  # ìƒˆë¡œ ì¶”ê°€
            'is_ai_prediction': any(word in content for word in ['ai predicts', 'ai based', 'energy crisis']),  # ìƒˆë¡œ ì¶”ê°€
        }
        
        return features
    
    def _calculate_sentiment_score(self, content: str) -> float:
        """ê°„ë‹¨í•œ ê°ì • ì ìˆ˜ ê³„ì‚°"""
        positive_words = ['approved', 'launched', 'bought', 'partnership', 'adoption', 'positive', 'surge', 'rally', 'breaks', 'crosses']
        negative_words = ['banned', 'rejected', 'hack', 'stolen', 'crash', 'plunge', 'lawsuit', 'prohibited']
        
        pos_count = sum(1 for word in positive_words if word in content)
        neg_count = sum(1 for word in negative_words if word in content)
        
        if pos_count + neg_count == 0:
            return 0.0
        
        return (pos_count - neg_count) / (pos_count + neg_count)
    
    def _get_fallback_prediction(self, article: Dict) -> Dict:
        """ML ì‚¬ìš© ë¶ˆê°€ ì‹œ í˜„ì‹¤ì  í´ë°± ì˜ˆì¸¡"""
        content = (article.get('title', '') + ' ' + article.get('description', '')).lower()
        
        # ë‰´ìŠ¤ íƒ€ì… ë¶„ë¥˜
        news_type = self._classify_news_type(article)
        pattern_info = self.news_reaction_patterns.get(news_type, self.news_reaction_patterns['macro_economic_general'])
        
        # íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡ ë²”ìœ„
        min_impact, max_impact = pattern_info['typical_range']
        
        # ì¤‘ê°„ê°’ ê³„ì‚°
        avg_impact = (min_impact + max_impact) / 2
        magnitude = abs(avg_impact)
        direction = 'bullish' if avg_impact > 0 else 'bearish' if avg_impact < 0 else 'neutral'
        
        return {
            'direction': direction,
            'magnitude': magnitude,
            'confidence': 0.7,
            'timeframe': self._get_realistic_timeframe(article),
            'risk_level': pattern_info['actual_impact']
        }
    
    def _format_smart_strategy(self, news_type: str, ml_prediction: Dict, article: Dict) -> str:
        """í˜„ì‹¤ì  ì „ëµ ì œì•ˆ"""
        direction = ml_prediction.get('direction', 'neutral')
        magnitude = ml_prediction.get('magnitude', 0.5)
        confidence = ml_prediction.get('confidence', 0.5)
        
        # ê¸°ë³¸ íŒ¨í„´ ì •ë³´
        pattern_info = self.news_reaction_patterns.get(news_type, {})
        
        strategy_lines = []
        
        # ğŸ”¥ğŸ”¥ AI ì˜ˆì¸¡ ê´€ë ¨ íŠ¹ë³„ ì²˜ë¦¬ (ìƒˆë¡œ ì¶”ê°€)
        if news_type == 'ai_prediction':
            strategy_lines.append("ğŸ¯ <b>AI ì˜ˆì¸¡ - ì‹ ì¤‘í•œ ì ‘ê·¼</b>")
            strategy_lines.append("â€¢ ì¶”ì¸¡ì„± ì •ë³´ë¡œ ì‹¤ì œ ì˜í–¥ ì œí•œì ")
            strategy_lines.append("â€¢ í€ë”ë©˜í„¸ ë¶„ì„ê³¼ ë¬´ê´€í•œ ì˜ˆì¸¡")
            strategy_lines.append("â€¢ íˆ¬ê¸°ì  ê±°ë˜ë§Œ ê³ ë ¤")
            
        elif news_type == 'energy_crisis_prediction':
            strategy_lines.append("ğŸ¯ <b>ì—ë„ˆì§€ ìœ„ê¸° ì˜ˆì¸¡ - ê°€ì„¤ì  ì‹œë‚˜ë¦¬ì˜¤</b>")
            strategy_lines.append("â€¢ 25ë§Œ ë‹¬ëŸ¬ ì˜ˆì¸¡ì€ ê·¹ë„ë¡œ ë‚™ê´€ì ")
            strategy_lines.append("â€¢ ì‹¤ì œ ì—ë„ˆì§€ ìœ„ê¸° ë°œìƒ ê°€ëŠ¥ì„± ë‚®ìŒ")
            strategy_lines.append("â€¢ ì¥ê¸° íˆ¬ì ì˜ì‚¬ê²°ì •ì— ë¶€ì í•©")
            
        # ë‰´ìŠ¤ íƒ€ì…ë³„ íŠ¹í™” ì „ëµ
        elif news_type == 'corporate_structured_product':
            strategy_lines.append("ğŸ¯ <b>êµ¬ì¡°í™” ìƒí’ˆ - ë¯¸ë¯¸í•œ ì˜í–¥</b>")
            strategy_lines.append("â€¢ ì§ì ‘ì ì¸ BTC ìˆ˜ìš” ì°½ì¶œ ì—†ìŒ")
            strategy_lines.append("â€¢ ë‹¨ê¸° ìŠ¤ìº˜í•‘ë§Œ ê³ ë ¤")
            strategy_lines.append("â€¢ ì¥ê¸° íˆ¬ì ì˜ì‚¬ê²°ì •ì— ì˜í–¥ ì—†ìŒ")
            
        elif news_type == 'corporate_purchase_direct':
            if magnitude > 0.8:
                strategy_lines.append("ğŸ¯ <b>ì§ì ‘ ë§¤ì… - ì ê·¹ ë§¤ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤</b>")
                strategy_lines.append("â€¢ ì‹¤ì œ BTC ìˆ˜ìš” ì¦ê°€")
                strategy_lines.append("â€¢ ë¶„í•  ë§¤ìˆ˜ í›„ ì¤‘ê¸° ë³´ìœ ")
            else:
                strategy_lines.append("ğŸ¯ <b>ì§ì ‘ ë§¤ì… - ì‹ ì¤‘ ë§¤ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤</b>")
                strategy_lines.append("â€¢ ì†ŒëŸ‰ í…ŒìŠ¤íŠ¸ í›„ ì¶”ê°€ ì§„ì…")
                
        elif news_type == 'etf_approval':
            strategy_lines.append("ğŸ¯ <b>ETF ìŠ¹ì¸ - ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”</b>")
            strategy_lines.append("â€¢ ë°œí‘œ ì§í›„ ë¹ ë¥¸ ì§„ì…")
            strategy_lines.append("â€¢ 2-4ì‹œê°„ ë‚´ ìˆ˜ìµ ì‹¤í˜„ ê³ ë ¤")
            
        elif news_type == 'etf_rejection':
            strategy_lines.append("ğŸ¯ <b>ETF ê±°ë¶€ - ì—­ë§¤ë§¤ ê¸°íšŒ</b>")
            strategy_lines.append("â€¢ ê¸‰ë½ ì‹œ ë¶„í•  ë§¤ìˆ˜")
            strategy_lines.append("â€¢ 6-12ì‹œê°„ ë‚´ íšŒë³µ ê¸°ëŒ€")
            
        elif news_type == 'trade_tariffs':
            strategy_lines.append("ğŸ¯ <b>ê´€ì„¸ ì •ì±… - ë‹¨ê¸° í•˜ë½ í›„ íšŒë³µ</b>")
            strategy_lines.append("â€¢ ì´ˆê¸° ë§¤ë„ ì••ë°• í›„ ì•ˆì •í™”")
            strategy_lines.append("â€¢ í•˜ë½ ì‹œ ë¶„í•  ë§¤ìˆ˜ ê¸°íšŒ")
            
        elif news_type == 'inflation_data':
            strategy_lines.append("ğŸ¯ <b>ì¸í”Œë ˆì´ì…˜ í—¤ì§€ - ì™„ë§Œí•œ ìƒìŠ¹</b>")
            strategy_lines.append("â€¢ í—¤ì§€ ìˆ˜ìš”ë¡œ ì ì§„ì  ìƒìŠ¹")
            strategy_lines.append("â€¢ ì¥ê¸° ë³´ìœ  ê´€ì ì—ì„œ ìœ ë¦¬")
            
        elif news_type == 'price_milestone':  # ìƒˆë¡œ ì¶”ê°€
            strategy_lines.append("ğŸ¯ <b>ê°€ê²© ëŒíŒŒ - ì‹¬ë¦¬ì  íš¨ê³¼</b>")
            strategy_lines.append("â€¢ ì¼ë°˜ íˆ¬ìì ê´€ì‹¬ë„ê°€ í•µì‹¬")
            strategy_lines.append("â€¢ FOMO í™•ì‚° ì‹œ ì¶”ê°€ ìƒìŠ¹ ê°€ëŠ¥")
            strategy_lines.append("â€¢ ê²€ìƒ‰ëŸ‰/ì†Œì…œ í™œë™ ëª¨ë‹ˆí„°ë§ í•„ìš”")
            
        elif direction == 'bearish' and confidence > 0.6:
            strategy_lines.append("ğŸ¯ <b>ë°©ì–´ ë° ì—­ë§¤ë§¤ ì‹œë‚˜ë¦¬ì˜¤</b>")
            strategy_lines.append("â€¢ ê¸°ì¡´ í¬ì§€ì…˜ ë¶€ë¶„ ì²­ì‚°")
            strategy_lines.append("â€¢ ê³¼ë§¤ë„ ì‹œ ì—­ë§¤ë§¤ ì¤€ë¹„")
        else:
            strategy_lines.append("ğŸ¯ <b>ì¤‘ë¦½ ê´€ë§</b>")
            strategy_lines.append("â€¢ ì¶”ê°€ ì‹ í˜¸ ëŒ€ê¸°")
            strategy_lines.append("â€¢ ì†ŒëŸ‰ ì–‘ë°©í–¥ í—·ì§€ ê³ ë ¤")
        
        # í˜„ì‹¤ì ì¸ íƒ€ì´ë° ì •ë³´
        if pattern_info.get('pattern'):
            strategy_lines.append(f"â±ï¸ <b>ë°˜ì‘ íŒ¨í„´</b>: {pattern_info['pattern']}")
        
        # í˜„ì‹¤ì ì¸ ì§€ì† ê¸°ê°„
        if pattern_info.get('duration'):
            strategy_lines.append(f"ğŸ“… <b>ì˜í–¥ ì§€ì†</b>: {pattern_info['duration']}")
        else:
            # ê¸°ë³¸ê°’ - ë‰´ìŠ¤ íƒ€ì…ì— ë”°ë¼
            if news_type in ['ai_prediction', 'energy_crisis_prediction']:
                strategy_lines.append(f"ğŸ“… <b>ì˜í–¥ ì§€ì†</b>: 1-4ì‹œê°„ (ë¯¸ë¯¸)")
            elif news_type == 'corporate_structured_product':
                strategy_lines.append(f"ğŸ“… <b>ì˜í–¥ ì§€ì†</b>: 2-6ì‹œê°„ (ë¯¸ë¯¸)")
            elif news_type in ['etf_approval', 'etf_rejection']:
                strategy_lines.append(f"ğŸ“… <b>ì˜í–¥ ì§€ì†</b>: 12-24ì‹œê°„")
            elif news_type == 'price_milestone':
                strategy_lines.append(f"ğŸ“… <b>ì˜í–¥ ì§€ì†</b>: 4-12ì‹œê°„ (FOMO ì˜ì¡´)")
            else:
                strategy_lines.append(f"ğŸ“… <b>ì˜í–¥ ì§€ì†</b>: 6-12ì‹œê°„")
        
        # ì‹¤ì œ ì˜í–¥ë„ í‘œì‹œ
        actual_impact = pattern_info.get('actual_impact', 'medium')
        impact_text = {
            'high': 'ë†’ìŒ âš¡',
            'medium': 'ë³´í†µ ğŸ“Š', 
            'low': 'ë‚®ìŒ ğŸ“‰',
            'minimal': 'ë¯¸ë¯¸ ğŸ’­'
        }.get(actual_impact, 'ë³´í†µ ğŸ“Š')
        
        strategy_lines.append(f"ğŸ² <b>ì‹¤ì œ ì˜í–¥ë„</b>: {impact_text} (ì‹ ë¢°ë„: {confidence:.0%})")
        
        return "\n".join(strategy_lines)
    
    def _generate_smart_summary_with_analysis(self, title: str, description: str, company: str = "", news_type: str = "") -> str:
        """ğŸ”¥ğŸ”¥ Claude APIë¥¼ í™œìš©í•œ ìŠ¤ë§ˆíŠ¸ ë¶„ì„ - ì‹¤ì œ ë‰´ìŠ¤ ë‚´ìš© ë¶„ì„"""
        try:
            content = (title + " " + description).lower()
            summary_parts = []
            
            # ğŸ”¥ğŸ”¥ AI ì˜ˆì¸¡ ê´€ë ¨ íŠ¹ë³„ ì²˜ë¦¬ (ìƒˆë¡œ ì¶”ê°€)
            if news_type in ['ai_prediction', 'energy_crisis_prediction']:
                if 'energy crisis' in content and '250000' in content:
                    summary_parts.append("AI ê¸°ë°˜ ë¶„ì„ì—ì„œ ì—ë„ˆì§€ ìœ„ê¸°ê°€ ë¹„íŠ¸ì½”ì¸ì„ 25ë§Œ ë‹¬ëŸ¬ê¹Œì§€ ëŒì–´ì˜¬ë¦´ ìˆ˜ ìˆë‹¤ëŠ” ì˜ˆì¸¡ì„ ì œì‹œí–ˆë‹¤.")
                    summary_parts.append("í•˜ì§€ë§Œ ì´ëŠ” ê·¹ë„ë¡œ ë‚™ê´€ì ì¸ ê°€ì •ì— ê¸°ë°˜í•œ ì¶”ì¸¡ì„± ì˜ˆì¸¡ìœ¼ë¡œ, ì‹¤ì œ ì‹œì¥ ìš”ì¸ë“¤ê³¼ëŠ” ê±°ë¦¬ê°€ ìˆë‹¤.")
                    summary_parts.append("íˆ¬ììë“¤ì€ ì´ëŸ° ê·¹ë‹¨ì  ì˜ˆì¸¡ë³´ë‹¤ëŠ” ì‹¤ì œ ê³µê¸‰-ìˆ˜ìš” í€ë”ë©˜í„¸ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤.")
                else:
                    summary_parts.append("AI ê¸°ë°˜ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ì˜ˆì¸¡ì´ ë°œí‘œë˜ì—ˆë‹¤.")
                    summary_parts.append("AI ì˜ˆì¸¡ ëª¨ë¸ì˜ ì •í™•ì„±ê³¼ ê·¼ê±°ì— ëŒ€í•œ ê²€ì¦ì´ í•„ìš”í•œ ìƒí™©ì´ë‹¤.")
                    summary_parts.append("ì‹œì¥ì€ ì¶”ì¸¡ì„± ì˜ˆì¸¡ë³´ë‹¤ëŠ” ì‹¤ì œ ìˆ˜ê¸‰ê³¼ ê·œì œ ë™í–¥ì— ë” ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•œë‹¤.")
                
                return " ".join(summary_parts)
            
            # ğŸ”¥ğŸ”¥ ë¹„íŠ¸ì½”ì¸ ê°€ê²© ê´€ë ¨ íŠ¹ë³„ ì²˜ë¦¬ - ë” ì •êµí•˜ê²Œ
            if any(word in content for word in ['crosses', '100k', '$100', 'milestone']) and 'bitcoin' in content:
                if any(word in content for word in ['search', 'google', 'interest', 'attention']):
                    summary_parts.append("ë¹„íŠ¸ì½”ì¸ì´ 10ë§Œ ë‹¬ëŸ¬ë¥¼ ëŒíŒŒí–ˆì§€ë§Œ êµ¬ê¸€ ê²€ìƒ‰ëŸ‰ì€ ì˜ˆìƒë³´ë‹¤ ë‚®ì€ ìˆ˜ì¤€ì„ ë³´ì´ê³  ìˆë‹¤.")
                    summary_parts.append("ì´ëŠ” ê¸°ê´€ íˆ¬ìì ì¤‘ì‹¬ì˜ ìƒìŠ¹ìœ¼ë¡œ ì¼ë°˜ íˆ¬ììë“¤ì˜ ê´€ì‹¬ì€ ì•„ì§ ì œí•œì ì„ì„ ì‹œì‚¬í•œë‹¤.")
                    summary_parts.append("í–¥í›„ ì†Œë§¤ íˆ¬ììë“¤ì˜ FOMOê°€ ë³¸ê²©í™”ë  ê²½ìš° ì¶”ê°€ ìƒìŠ¹ ì—¬ë ¥ì´ ìˆì„ ê²ƒìœ¼ë¡œ ë¶„ì„ëœë‹¤.")
                else:
                    summary_parts.append("ë¹„íŠ¸ì½”ì¸ì´ 10ë§Œ ë‹¬ëŸ¬ ì´ì •í‘œë¥¼ ëŒíŒŒí•˜ë©° ì—­ì‚¬ì ì¸ ìˆœê°„ì„ ê¸°ë¡í–ˆë‹¤.")
                    summary_parts.append("ì‹¬ë¦¬ì  ì €í•­ì„  ëŒíŒŒë¡œ ë‹¨ê¸°ì ì¸ ìƒìŠ¹ ëª¨ë©˜í…€ì´ í˜•ì„±ë  ìˆ˜ ìˆë‹¤.")
                    summary_parts.append("í•˜ì§€ë§Œ ê³¼ì—´ êµ¬ê°„ì—ì„œëŠ” ìˆ˜ìµ ì‹¤í˜„ ì••ë°•ë„ ë™ì‹œì— ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.")
                
                return " ".join(summary_parts)
            
            # êµ¬ì¡°í™” ìƒí’ˆ íŠ¹ë³„ ì²˜ë¦¬
            if any(word in content for word in ['structured', 'bonds', 'linked', 'exposure']):
                if 'sberbank' in content:
                    summary_parts.append("ëŸ¬ì‹œì•„ ìµœëŒ€ ì€í–‰ ìŠ¤ë² ë¥´ë°©í¬ê°€ ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì— ì—°ë™ëœ êµ¬ì¡°í™” ì±„ê¶Œì„ ì¶œì‹œí–ˆë‹¤.")
                    summary_parts.append("ì´ëŠ” ì§ì ‘ì ì¸ ë¹„íŠ¸ì½”ì¸ ë§¤ìˆ˜ê°€ ì•„ë‹Œ ê°€ê²© ì¶”ì  ìƒí’ˆìœ¼ë¡œ, ì‹¤ì œ BTC ìˆ˜ìš” ì°½ì¶œ íš¨ê³¼ëŠ” ì œí•œì ì´ë‹¤.")
                    summary_parts.append("ëŸ¬ì‹œì•„ ì œì¬ ìƒí™©ê³¼ OTC ê±°ë˜ë¡œ ì¸í•´ ê¸€ë¡œë²Œ ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì¦‰ê°ì  ì˜í–¥ì€ ë¯¸ë¯¸í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.")
                else:
                    summary_parts.append("ìƒˆë¡œìš´ ë¹„íŠ¸ì½”ì¸ ì—°ê³„ êµ¬ì¡°í™” ìƒí’ˆì´ ì¶œì‹œë˜ì—ˆë‹¤.")
                    summary_parts.append("ì§ì ‘ì ì¸ ë¹„íŠ¸ì½”ì¸ ìˆ˜ìš”ë³´ë‹¤ëŠ” ê°„ì ‘ì  ë…¸ì¶œ ì œê³µì— ì¤‘ì ì„ ë‘” ìƒí’ˆìœ¼ë¡œ í‰ê°€ëœë‹¤.")
                    summary_parts.append("ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì‹¤ì§ˆì  ì˜í–¥ì€ ì œí•œì ì¼ ê²ƒìœ¼ë¡œ ì „ë§ëœë‹¤.")
                
                return " ".join(summary_parts)
            
            # ê¸°ì—…ëª…ê³¼ í–‰ë™ ë§¤ì¹­
            if company:
                company_lower = company.lower()
                
                # ë§ˆì´í¬ë¡œìŠ¤íŠ¸ë˜í‹°ì§€ ì²˜ë¦¬
                if company_lower == 'microstrategy':
                    if 'bought' in content or 'purchase' in content:
                        btc_amounts = re.findall(r'(\d+(?:,\d+)*)\s*(?:btc|bitcoin)', content)
                        if btc_amounts:
                            summary_parts.append(f"ë§ˆì´í¬ë¡œìŠ¤íŠ¸ë˜í‹°ì§€ê°€ ë¹„íŠ¸ì½”ì¸ {btc_amounts[0]}ê°œë¥¼ ì§ì ‘ ë§¤ì…í–ˆë‹¤.")
                        else:
                            summary_parts.append("ë§ˆì´í¬ë¡œìŠ¤íŠ¸ë˜í‹°ì§€ê°€ ë¹„íŠ¸ì½”ì¸ì„ ì¶”ê°€ ë§¤ì…í–ˆë‹¤.")
                        
                        summary_parts.append("ì´ëŠ” ì‹¤ì œ BTC ìˆ˜ìš” ì¦ê°€ë¥¼ ì˜ë¯¸í•˜ë©°, ê¸°ì—… ì¬ë¬´ ì „ëµì˜ ì¼í™˜ìœ¼ë¡œ ì‹œì¥ì— ê¸ì •ì  ì‹ í˜¸ë¥¼ ë³´ë‚¸ë‹¤.")
                        summary_parts.append("ëŒ€í˜• ê¸°ì—…ì˜ ì§€ì†ì ì¸ ë¹„íŠ¸ì½”ì¸ ë§¤ì…ì€ ì‹œì¥ ì‹ ë¢°ë„ í–¥ìƒì— ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.")
                
                # í…ŒìŠ¬ë¼ ì²˜ë¦¬
                elif company_lower == 'tesla':
                    if 'bought' in content or 'purchase' in content:
                        summary_parts.append("í…ŒìŠ¬ë¼ê°€ ë¹„íŠ¸ì½”ì¸ ì§ì ‘ ë§¤ì…ì„ ì¬ê°œí–ˆë‹¤.")
                        summary_parts.append("ì¼ë¡  ë¨¸ìŠ¤í¬ì˜ ì˜í–¥ë ¥ê³¼ í•¨ê»˜ ì‹œì¥ì— ìƒë‹¹í•œ ê´€ì‹¬ì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¬ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.")
                        summary_parts.append("ê¸°ì—…ì˜ ë¹„íŠ¸ì½”ì¸ ì±„íƒ í™•ì‚°ì— ê¸ì •ì  ì˜í–¥ì„ ë¯¸ì¹  ì „ë§ì´ë‹¤.")
                
                # ë¸”ë™ë¡ ì²˜ë¦¬
                elif company_lower == 'blackrock':
                    if 'etf' in content:
                        if 'approved' in content:
                            summary_parts.append("ì„¸ê³„ ìµœëŒ€ ìì‚°ìš´ìš©ì‚¬ ë¸”ë™ë¡ì˜ ë¹„íŠ¸ì½”ì¸ ETFê°€ ìŠ¹ì¸ë˜ì—ˆë‹¤.")
                            summary_parts.append("ì´ëŠ” ê¸°ê´€ ìê¸ˆì˜ ëŒ€ê·œëª¨ ìœ ì… ê°€ëŠ¥ì„±ì„ ì—´ì–´ì£¼ëŠ” íšê¸°ì  ì‚¬ê±´ì´ë‹¤.")
                            summary_parts.append("ë¹„íŠ¸ì½”ì¸ ì‹œì¥ì˜ ì œë„í™”ì™€ ì£¼ë¥˜ ì±„íƒì— ì¤‘ìš”í•œ ì´ì •í‘œê°€ ë  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.")
                        else:
                            summary_parts.append("ë¸”ë™ë¡ì˜ ë¹„íŠ¸ì½”ì¸ ETF ê´€ë ¨ ì¤‘ìš”í•œ ë°œí‘œê°€ ìˆì—ˆë‹¤.")
                            summary_parts.append("ì„¸ê³„ ìµœëŒ€ ìì‚°ìš´ìš©ì‚¬ì˜ ì›€ì§ì„ì´ ì‹œì¥ì— ì£¼ëª©ë°›ê³  ìˆë‹¤.")
                            summary_parts.append("ê¸°ê´€ íˆ¬ììë“¤ì˜ ë¹„íŠ¸ì½”ì¸ ê´€ì‹¬ë„ê°€ ë†’ì•„ì§€ê³  ìˆìŒì„ ì‹œì‚¬í•œë‹¤.")
            
            # ê±°ì‹œê²½ì œ íŒ¨í„´ ì²˜ë¦¬
            if not summary_parts:
                # ê´€ì„¸ ê´€ë ¨
                if any(word in content for word in ['trump', 'tariffs', 'trade war']):
                    summary_parts.append("ë¯¸êµ­ì˜ ìƒˆë¡œìš´ ê´€ì„¸ ì •ì±…ì´ ë°œí‘œë˜ì—ˆë‹¤.")
                    summary_parts.append("ë¬´ì—­ ë¶„ìŸ ìš°ë ¤ë¡œ ì¸í•´ ë‹¨ê¸°ì ìœ¼ë¡œ ë¦¬ìŠ¤í¬ ìì‚°ì— ë¶€ë‹´ì´ ë  ìˆ˜ ìˆë‹¤.")
                    summary_parts.append("í•˜ì§€ë§Œ ë‹¬ëŸ¬ ì•½ì„¸ ìš”ì¸ì´ ë¹„íŠ¸ì½”ì¸ì—ëŠ” ì¤‘ì¥ê¸°ì ìœ¼ë¡œ ìœ ë¦¬í•  ê²ƒìœ¼ë¡œ ë¶„ì„ëœë‹¤.")
                
                # ì¸í”Œë ˆì´ì…˜ ê´€ë ¨
                elif any(word in content for word in ['inflation', 'cpi']):
                    summary_parts.append("ìµœì‹  ì¸í”Œë ˆì´ì…˜ ë°ì´í„°ê°€ ë°œí‘œë˜ì—ˆë‹¤.")
                    summary_parts.append("ì¸í”Œë ˆì´ì…˜ í—¤ì§€ ìì‚°ìœ¼ë¡œì„œ ë¹„íŠ¸ì½”ì¸ì— ëŒ€í•œ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆë‹¤.")
                    summary_parts.append("ì‹¤ë¬¼ ìì‚° ëŒ€ë¹„ ìš°ì›”í•œ ì„±ê³¼ë¥¼ ë³´ì´ë©° íˆ¬ììë“¤ì˜ ì£¼ëª©ì„ ë°›ê³  ìˆë‹¤.")
                
                # ETF ê´€ë ¨
                elif 'etf' in content:
                    if 'approved' in content or 'approval' in content:
                        summary_parts.append("ë¹„íŠ¸ì½”ì¸ í˜„ë¬¼ ETF ìŠ¹ì¸ ì†Œì‹ì´ ì „í•´ì¡Œë‹¤.")
                        summary_parts.append("ETF ìŠ¹ì¸ì€ ê¸°ê´€ íˆ¬ììë“¤ì˜ ëŒ€ê·œëª¨ ìê¸ˆ ìœ ì…ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì¤‘ìš”í•œ ì´ì •í‘œë‹¤.")
                        summary_parts.append("ë¹„íŠ¸ì½”ì¸ ì‹œì¥ì˜ ì„±ìˆ™ë„ì™€ ì œë„ì  ì¸ì •ì„ ë³´ì—¬ì£¼ëŠ” ìƒì§•ì  ì‚¬ê±´ìœ¼ë¡œ í‰ê°€ëœë‹¤.")
                    elif 'rejected' in content or 'delay' in content:
                        summary_parts.append("ë¹„íŠ¸ì½”ì¸ ETF ìŠ¹ì¸ì´ ì§€ì—°ë˜ê±°ë‚˜ ê±°ë¶€ë˜ì—ˆë‹¤.")
                        summary_parts.append("ë‹¨ê¸°ì  ì‹¤ë§ê°ì€ ìˆìœ¼ë‚˜, ì§€ì†ì ì¸ ì‹ ì²­ì€ ê²°êµ­ ìŠ¹ì¸ ê°€ëŠ¥ì„±ì„ ë†’ì´ê³  ìˆë‹¤.")
                        summary_parts.append("ì‹œì¥ì€ ì´ë¯¸ ETF ìŠ¹ì¸ì„ ê¸°ì •ì‚¬ì‹¤ë¡œ ë°›ì•„ë“¤ì´ê³  ìˆì–´ ì¥ê¸° ì „ë§ì€ ê¸ì •ì ì´ë‹¤.")
                
                # Fed ê¸ˆë¦¬ ê´€ë ¨
                elif 'fed' in content or 'rate' in content:
                    if 'cut' in content or 'lower' in content:
                        summary_parts.append("ì—°ì¤€ì˜ ê¸ˆë¦¬ ì¸í•˜ ê²°ì •ì´ ë°œí‘œë˜ì—ˆë‹¤.")
                        summary_parts.append("ê¸ˆë¦¬ ì¸í•˜ëŠ” ìœ ë™ì„± ì¦ê°€ë¥¼ í†µí•´ ë¹„íŠ¸ì½”ì¸ê³¼ ê°™ì€ ë¦¬ìŠ¤í¬ ìì‚°ì— ê¸ì •ì  ì˜í–¥ì„ ë¯¸ì¹œë‹¤.")
                        summary_parts.append("ì €ê¸ˆë¦¬ í™˜ê²½ì—ì„œ ëŒ€ì•ˆ íˆ¬ìì²˜ë¡œì„œ ë¹„íŠ¸ì½”ì¸ì˜ ë§¤ë ¥ë„ê°€ ë”ìš± ë¶€ê°ë  ì „ë§ì´ë‹¤.")
                    elif 'hike' in content or 'increase' in content:
                        summary_parts.append("ì—°ì¤€ì˜ ê¸ˆë¦¬ ì¸ìƒ ê²°ì •ì´ ë°œí‘œë˜ì—ˆë‹¤.")
                        summary_parts.append("ë‹¨ê¸°ì ìœ¼ë¡œëŠ” ë¶€ë‹´ì´ì§€ë§Œ ì¸í”Œë ˆì´ì…˜ í—¤ì§€ ìì‚°ìœ¼ë¡œì„œì˜ ë¹„íŠ¸ì½”ì¸ ê°€ì¹˜ëŠ” ì§€ì†ë  ê²ƒì´ë‹¤.")
                        summary_parts.append("ê³ ê¸ˆë¦¬ í™˜ê²½ì—ì„œë„ ë””ì§€í„¸ ê¸ˆìœ¼ë¡œì„œì˜ ì—­í• ì€ ë³€í•¨ì—†ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.")
                
                # ê¸°ë³¸ ì¼€ì´ìŠ¤ - ì œëª© ë¶„ì„
                else:
                    # ì‹¤ì œ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•´ì„œ ë¶„ì„
                    if any(word in title.lower() for word in ['prediction', 'forecast', 'expects', 'predicts']):
                        summary_parts.append("ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì— ëŒ€í•œ ìƒˆë¡œìš´ ì˜ˆì¸¡ ë¶„ì„ì´ ë°œí‘œë˜ì—ˆë‹¤.")
                        summary_parts.append("ì˜ˆì¸¡ì˜ ë°©ë²•ë¡ ê³¼ ê·¼ê±°ì— ëŒ€í•œ ë©´ë°€í•œ ê²€í† ê°€ í•„ìš”í•œ ìƒí™©ì´ë‹¤.")
                        summary_parts.append("íˆ¬ììë“¤ì€ ì¶”ì¸¡ì„± ì˜ˆì¸¡ë³´ë‹¤ëŠ” ì‹¤ì œ ì‹œì¥ í€ë”ë©˜í„¸ì— ì§‘ì¤‘í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤.")
                    else:
                        summary_parts.append("ë¹„íŠ¸ì½”ì¸ ì‹œì¥ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ” ë°œí‘œê°€ ìˆì—ˆë‹¤.")
                        summary_parts.append("íˆ¬ììë“¤ì€ ì´ë²ˆ ì†Œì‹ì˜ ì‹¤ì œ ì‹œì¥ ì˜í–¥ì„ ë©´ë°€íˆ ë¶„ì„í•˜ê³  ìˆë‹¤.")
                        summary_parts.append("ë‹¨ê¸° ë³€ë™ì„±ì€ ìˆê² ì§€ë§Œ ì¥ê¸° íŠ¸ë Œë“œì—ëŠ” í° ë³€í™”ê°€ ì—†ì„ ê²ƒìœ¼ë¡œ ì „ë§ëœë‹¤.")
